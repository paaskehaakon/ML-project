{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haakon\n",
    "import lightgbm as lgb  # standard alias\n",
    "from lightgbm import plot_importance\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from catboost import CatBoostRegressor\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "train = pd.read_csv('../feature_engineering/train_set.csv')\n",
    "test = pd.read_csv('../feature_engineering/test_set.csv')\n",
    "#train_data = pd.read_csv('../data/stores_train.csv')\n",
    "\n",
    "\n",
    "train['lv1'] = train['lv1'].astype(object)\n",
    "test['lv1'] = test['lv1'].astype(object)\n",
    "\n",
    "train['lv2'] = train['lv2'].astype(object)\n",
    "test['lv2'] = test['lv2'].astype(object)\n",
    "\n",
    "#mall as caategory\n",
    "train['lv2'] = train['lv2'].astype(object)\n",
    "test['lv2'] = test['lv2'].astype(object)\n",
    "\n",
    "import re\n",
    "train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "y_train = train['revenue']\n",
    "train = train.iloc[: , :-1]\n",
    "\n",
    "# For working\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# For Kaggle\n",
    "X_train = train\n",
    "X_test = test\n",
    "\n",
    "# Save store ids, then remove this column\n",
    "store_ids = X_test['store_id'].to_numpy()\n",
    "ids = pd.DataFrame(store_ids)\n",
    "ids.rename(columns={0 :'id'}, inplace=True )\n",
    "\n",
    "#X_train = X_train.drop('store_id', axis=1)\n",
    "X_test = X_test.drop('store_id', axis=1)\n",
    "#X_train = X_train.drop(columns=X_train.columns[0], axis=1)\n",
    "#X_test = X_test.drop(columns=X_test.columns[0], axis=1)\n",
    "\n",
    "#X_train = X_train.drop('grunnkrets_id', axis=1)\n",
    "#X_test = X_test.drop('grunnkrets_id', axis=1)\n",
    "X_test = X_test.drop('mall_dummy', axis=1)\n",
    "#remove nan\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "y_train = y_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "\n",
    "def lgbm():\n",
    "#Hyper parameters\n",
    "    hyper_params = {\n",
    "        'task': 'train',\n",
    "        #'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': ['rmse'],\n",
    "        'learning_rate': 0.005,\n",
    "        \"max_depth\": 8,\n",
    "        \"num_leaves\": 128,  \n",
    "        \"num_iterations\": 1000\n",
    "    }\n",
    "\n",
    "    #fit the model takes some time\n",
    "    gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "    gbm.fit(X_train, y_train)\n",
    "    lgb.plot_importance(\n",
    "        gbm\n",
    "    )\n",
    "    print(\"fit\")\n",
    "    #predict\n",
    "    y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "\n",
    "    \n",
    "\n",
    "    #generate csv file of id and prediction\n",
    "    predicted = pd.DataFrame(y_pred, columns = ['predicted'])\n",
    "    output = pd.concat([ids,predicted],axis=1)\n",
    "    output.to_csv('lgbm.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "def catboost():\n",
    "    model = CatBoostRegressor(iterations=1000,\n",
    "                            learning_rate=0.005,\n",
    "                            depth=12,\n",
    "                            loss_function= 'RMSE')\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Get predictions\n",
    "    preds = model.predict(X_test)\n",
    "    preds = np.expm1(preds)\n",
    "\n",
    "    #generate csv file of id and prediction\n",
    "    predicted = pd.DataFrame(preds, columns = ['predicted'])\n",
    "    output = pd.concat([ids,predicted],axis=1)\n",
    "    output.to_csv('cat.csv',index=False)\n",
    "\n",
    "lgbm()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb  # standard alias\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from catboost import CatBoostRegressor\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "train = pd.read_csv('../no_nan_train.csv')\n",
    "test = pd.read_csv('../no_nan_test.csv')\n",
    "\n",
    "x_test = test\n",
    "x_train = train.drop('revenue', axis=1)\n",
    "y_train = train['revenue']\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train, train['revenue'], test_size=0.2, random_state=42)\n",
    "\n",
    "def cat():\n",
    "    model = CatBoostRegressor(iterations=1000,\n",
    "                                learning_rate=0.005,\n",
    "                                depth=12,\n",
    "                                loss_function= 'RMSE')\n",
    "    # Fit model\n",
    "    model.fit(x_train, y_train)\n",
    "    # Get predictions\n",
    "    preds = model.predict(x_test)\n",
    "    preds = np.expm1(preds)\n",
    "    predicted = pd.DataFrame(preds, columns = ['predicted'])\n",
    "\n",
    "    output = pd.concat([ids,predicted],axis=1)\n",
    "    output.to_csv('lgbm.csv',index=False)\n",
    "    df = pd.read_csv('output_for_submission.csv')\n",
    "    df['predicted'] = df['predicted'].shift(-1)\n",
    "    df.to_csv('shifted.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Hyper parameters\n",
    "hyper_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': ['l1','l2'],\n",
    "    'learning_rate': 0.005,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 10,\n",
    "    'verbose': 0,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 128,  \n",
    "    \"max_bin\": 512,\n",
    "    \"num_iterations\": 1000\n",
    "}\n",
    "\n",
    "#fit the model takes some time\n",
    "gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "gbm.fit(X_train, y_train)\n",
    "print(\"fit\")\n",
    "#predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "y_pred = np.expm1(y_pred)\n",
    "\n",
    "#generate csv file of id and prediction\n",
    "predicted = pd.DataFrame(y_pred, columns = ['predicted'])\n",
    "output = pd.concat([ids,predicted],axis=1)\n",
    "output.to_csv('lgbm.csv',index=False)\n",
    "df = pd.read_csv('output_for_submission.csv')\n",
    "df['predicted'] = df['predicted'].shift(-1)\n",
    "df.to_csv('shifted.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from verstack import LGBMTuner\n",
    "# import the data\n",
    "train = pd.read_csv('../data/modified_data.csv')\n",
    "test = pd.read_csv('../data/modified_test_data.csv')\n",
    "test = test.drop('store_id', axis = 1)\n",
    "X = train.drop('revenue', axis = 1)\n",
    "X = X.drop('store_id', axis = 1)\n",
    "y = train['revenue']\n",
    "X = X.fillna(0)\n",
    "y = y.fillna(0)\n",
    "print(X.isnull().values.any())\n",
    "# tune the hyperparameters and fit the optimized model\n",
    "tuner = LGBMTuner(metric = 'rmsle') # <- the only required argument\n",
    "tuner.fit(X, y)\n",
    "# check the optimization log in the console.\n",
    "pred = tuner.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
