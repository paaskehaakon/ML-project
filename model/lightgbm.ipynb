{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haakon\n",
    "import lightgbm as lgb  # standard alias\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from catboost import CatBoostRegressor\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "train = pd.read_csv('../feature_engineering/train_set.csv')\n",
    "test = pd.read_csv('../feature_engineering/test_set.csv')\n",
    "#train_data = pd.read_csv('../data/stores_train.csv')\n",
    "\n",
    "import re\n",
    "train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "y_train = train['revenue']\n",
    "train = train.iloc[: , :-1]\n",
    "\n",
    "# For working\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# For Kaggle\n",
    "X_train = train\n",
    "X_test = test\n",
    "\n",
    "# Save store ids, then remove this column\n",
    "store_ids = X_test['store_id'].to_numpy()\n",
    "ids = pd.DataFrame(store_ids)\n",
    "ids.rename(columns={0 :'id'}, inplace=True )\n",
    "\n",
    "X_train = X_train.drop('store_id', axis=1)\n",
    "X_test = X_test.drop('store_id', axis=1)\n",
    "X_train = X_train.drop(columns=X_train.columns[0], axis=1)\n",
    "X_test = X_test.drop(columns=X_test.columns[0], axis=1)\n",
    "\n",
    "X_train = X_train.drop('grunnkrets_id', axis=1)\n",
    "X_test = X_test.drop('grunnkrets_id', axis=1)\n",
    "\n",
    "#remove nan\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "y_train = y_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "\n",
    "def lgbm():\n",
    "#Hyper parameters\n",
    "    hyper_params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': ['l1','l2'],\n",
    "        'learning_rate': 0.005,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 10,\n",
    "        'verbose': 0,\n",
    "        \"max_depth\": 8,\n",
    "        \"num_leaves\": 128,  \n",
    "        \"max_bin\": 512,\n",
    "        \"num_iterations\": 1000\n",
    "    }\n",
    "\n",
    "    #fit the model takes some time\n",
    "    gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "    gbm.fit(X_train, y_train)\n",
    "    print(\"fit\")\n",
    "    #predict\n",
    "    y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "\n",
    "    #generate csv file of id and prediction\n",
    "    predicted = pd.DataFrame(y_pred, columns = ['predicted'])\n",
    "    output = pd.concat([ids,predicted],axis=1)\n",
    "    output.to_csv('lgbm.csv',index=False)\n",
    "\n",
    "\n",
    "\"\"\" model = CatBoostRegressor(iterations=1000,\n",
    "                        learning_rate=0.005,\n",
    "                        depth=12,\n",
    "                        loss_function= 'RMSE')\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "# Get predictions\n",
    "preds = model.predict(X_test)\n",
    "preds = np.expm1(preds)\n",
    "\n",
    "#generate csv file of id and prediction\n",
    "predicted = pd.DataFrame(preds, columns = ['predicted'])\n",
    "output = pd.concat([ids,predicted],axis=1)\n",
    "output.to_csv('cat.csv',index=False) \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm2():\n",
    "    params = {\n",
    "    'task': 'train', \n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_leaves': 10,\n",
    "    'learnnig_rage': 0.05,\n",
    "    'metric': {'l2','l1'},\n",
    "    'verbose': -1\n",
    "    }\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                    train_set=lgb_train,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=30)\n",
    "    # prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Hyper parameters\n",
    "hyper_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': ['l1','l2'],\n",
    "    'learning_rate': 0.005,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 10,\n",
    "    'verbose': 0,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 128,  \n",
    "    \"max_bin\": 512,\n",
    "    \"num_iterations\": 1000\n",
    "}\n",
    "\n",
    "#fit the model takes some time\n",
    "gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "gbm.fit(X_train, y_train)\n",
    "print(\"fit\")\n",
    "#predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "y_pred = np.expm1(y_pred)\n",
    "\n",
    "#generate csv file of id and prediction\n",
    "predicted = pd.DataFrame(y_pred, columns = ['predicted'])\n",
    "output = pd.concat([ids,predicted],axis=1)\n",
    "output.to_csv('lgbm.csv',index=False)\n",
    "df = pd.read_csv('output_for_submission.csv')\n",
    "df['predicted'] = df['predicted'].shift(-1)\n",
    "df.to_csv('shifted.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from verstack import LGBMTuner\n",
    "# import the data\n",
    "train = pd.read_csv('../data/modified_data.csv')\n",
    "test = pd.read_csv('../data/modified_test_data.csv')\n",
    "test = test.drop('store_id', axis = 1)\n",
    "X = train.drop('revenue', axis = 1)\n",
    "X = X.drop('store_id', axis = 1)\n",
    "y = train['revenue']\n",
    "X = X.fillna(0)\n",
    "y = y.fillna(0)\n",
    "print(X.isnull().values.any())\n",
    "# tune the hyperparameters and fit the optimized model\n",
    "tuner = LGBMTuner(metric = 'rmsle') # <- the only required argument\n",
    "tuner.fit(X, y)\n",
    "# check the optimization log in the console.\n",
    "pred = tuner.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
