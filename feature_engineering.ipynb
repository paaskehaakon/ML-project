{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import geopy.distance\n",
    "from dis import dis\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import numpy\n",
    "from shapely import wkt\n",
    "from shapely import wkb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "from geopy.geocoders import Nominatim\n",
    "from os import path\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "train = pd.read_csv('data/stores_train.csv')\n",
    "test= pd.read_csv('data/stores_test.csv')\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "grunnkrets_age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "grunnkrets_households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "grunnkrets_income = pd.read_csv('data/grunnkrets_income_households.csv')\n",
    "grunnkrets_stripped = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "plaace_hierarchy = pd.read_csv('data/plaace_hierarchy.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_to_log(train_data):\n",
    "    if train_data._get_value(1, 'revenue') > 15:\n",
    "        train_data['revenue'] = np.log1p(train_data['revenue'])\n",
    "    return train_data\n",
    "\n",
    "def remove_zero_revenue(train_data):\n",
    "    train_data = train_data.loc[train_data[\"revenue\"] > 0.1]\n",
    "    train_data = train_data.reset_index(drop = True)\n",
    "    return train_data\n",
    "\n",
    "def remove_high_revenue(train_data):\n",
    "    train_data = train_data.loc[train_data[\"revenue\"] < 5]\n",
    "    train_data = train_data.reset_index()\n",
    "    return train_data\n",
    "\n",
    "def dist_to_all_km(lat, lon, df):\n",
    "\n",
    "    # coordinates in radians\n",
    "    lat1 = lat*math.pi/180\n",
    "    lon1 = lon*math.pi/180\n",
    "    lat2 = df['lat']*math.pi/180 # go through whole lat column\n",
    "    lon2 = df['lon']*math.pi/180 # go through whole lon column\n",
    "\n",
    "    # store original coordinates in new dataframe\n",
    "    distances = pd.DataFrame()\n",
    "    distances['lat'] = df['lat'].copy()\n",
    "    distances['lon'] = df['lon'].copy()\n",
    "\n",
    "    # calculate cartesian coordinates\n",
    "    R = 6371 # Earth radius in km\n",
    "    df['x'] = R*np.cos(lat2)*np.cos(lon2)\n",
    "    df['y'] = R*np.cos(lat2)*np.sin(lon2)\n",
    "    df['z'] = R*np.sin(lat2)\n",
    "    x1 = R*np.cos(lat1)*np.cos(lon1)\n",
    "    y1 = R*np.cos(lat1)*np.sin(lon1)\n",
    "    z1 = R*np.sin(lat1)\n",
    "\n",
    "    # calculate distance, store as new column in the distances dataframe\n",
    "    distances['dist'] = np.sqrt(np.square(df['x']-x1)+np.square(df['y']-y1)+np.square(df['z']-z1))\n",
    "\n",
    "    return distances['dist'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the initial dataset with every feature we want\n",
    "\n",
    "def lat_long_busstop():\n",
    "    busstops['geometry'] = gpd.GeoSeries.from_wkt(busstops['geometry'])\n",
    "    busstops['lat'] = busstops.geometry.apply(lambda x: x.y)\n",
    "    busstops['lon'] = busstops.geometry.apply(lambda x: x.x)\n",
    "\n",
    "\n",
    "def convert_nan(train_data):\n",
    "    # Replace NaN in mall_name and chain_name columns with 'No mall' and 'No chain'\n",
    "    train_data.mall_name = train_data.mall_name.fillna('No mall')\n",
    "    train_data.chain_name = train_data.chain_name.fillna('No chain')\n",
    "    train_data.address = train_data.address.fillna('No Address')\n",
    "    train_data['mall_name']= train_data['mall_name'].astype('category')\n",
    "    train_data['chain_name']= train_data['chain_name'].astype('category')\n",
    "    return train_data\n",
    "\n",
    "def combine_grunnkrets_and_data(train_data):\n",
    "    train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'municipality_name']], on='grunnkrets_id', how='left')\n",
    "    train_data.municipality_name = train_data.municipality_name.fillna('No municipality')\n",
    "    # we get a bunch of duplicates of store_ids...? Remove them.\n",
    "    train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    return train_data\n",
    "\n",
    "\n",
    "def create_lvl(train_data):\n",
    "    global plaace_hierarchy\n",
    "\n",
    "    train_data = pd.merge(train_data, plaace_hierarchy[['plaace_hierarchy_id', 'lv1', 'lv2', 'lv3']], on='plaace_hierarchy_id', how='outer')\n",
    "    train_data['lv1']= train_data['lv1'].astype('category')\n",
    "    train_data['lv2']= train_data['lv2'].astype('category')\n",
    "    train_data['lv3']= train_data['lv3'].astype('category')\n",
    "    \n",
    "    #drop the last broken columns\n",
    "    train_data = train_data.dropna(subset=['store_id'])\n",
    "    return train_data\n",
    "    \n",
    "def remove_zero_rev(train_data):\n",
    "    i = train_data[(train_data.revenue == 0)].index\n",
    "    train_data.drop(i)\n",
    "    train_data = train_data.reset_index()\n",
    "    return train_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUSSTOP FEATURES\n",
    "def busstops_wihin_distances(train_data): \n",
    "    train_data['busstops_within_50m'] = 0\n",
    "    train_data['busstops_within_100m'] = 0\n",
    "    train_data['busstops_within_400m'] = 0\n",
    "    train_data['busstops_within_800m'] = 0\n",
    "    train_data['busstops_within_1500m'] = 0\n",
    "\n",
    "\n",
    "    iter = 0\n",
    "\n",
    "    for index in range(len(train_data)):\n",
    "        one_to_all = dist_to_all_km(train_data._get_value(index, 'lat'), train_data._get_value(index, 'lon'), busstops)\n",
    "        one_to_all = one_to_all.to_frame()\n",
    "        one_to_all.rename( columns={0 :'a'}, inplace=True)\n",
    "        count50 = (one_to_all < 0.05).sum()\n",
    "        count100 = (one_to_all < 0.1).sum()\n",
    "        count400 = (one_to_all < 0.4).sum()\n",
    "        count800 = (one_to_all < 0.8).sum()\n",
    "        count1500 = (one_to_all < 1.5).sum()\n",
    "\n",
    "        iter += 1\n",
    "        print(str(iter) + \"/\" + str(len(train_data)))\n",
    "        train_data._set_value(index, 'busstops_within_50m', count50)\n",
    "        train_data._set_value(index, 'busstops_within_100m', count100)\n",
    "        train_data._set_value(index, 'busstops_within_400m', count400)\n",
    "        train_data._set_value(index, 'busstops_within_800m', count800)\n",
    "        train_data._set_value(index, 'busstops_within_1500m', count1500)\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRUNNKRETS FEATURES\n",
    "\n",
    "def prep_gk():\n",
    "    global grunnkrets_age\n",
    "    global grunnkrets_stripped\n",
    "    global train\n",
    "    grunnkrets_age['total_nbr_people'] = 0\n",
    "    grunnkrets_age = grunnkrets_age.drop_duplicates(subset=['grunnkrets_id'], keep='last') # if there is value for 2016 we keep it, otherwise 2015\n",
    "    grunnkrets_age = grunnkrets_age.fillna(0)\n",
    "    grunnkrets_age = grunnkrets_age.drop('year',axis=1)\n",
    "    grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(str)\n",
    "    grunnkrets_age['total_nbr_people'] = grunnkrets_age.sum(axis=1) # total number of inhabitants\n",
    "    grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(int)\n",
    "\n",
    "    number_stores = train['grunnkrets_id'].value_counts().rename_axis('grunnkrets_id').reset_index(name='store_counts_total') # Not including NaN (stores without a grunnkrets_id)\n",
    "    grunnkrets_stripped = pd.merge(grunnkrets_stripped, number_stores[['grunnkrets_id', 'store_counts_total']], on='grunnkrets_id', how='left')\n",
    "    grunnkrets_stripped.store_counts_total = grunnkrets_stripped.store_counts_total.fillna(0)\n",
    "    grunnkrets_stripped = pd.merge(grunnkrets_stripped, grunnkrets_age[['grunnkrets_id', 'total_nbr_people']], on='grunnkrets_id', how='left')\n",
    "    grunnkrets_stripped['nbr_people_per_store_in_grunnkrets'] = grunnkrets_stripped['total_nbr_people']/grunnkrets_stripped['store_counts_total']\n",
    "\n",
    "\n",
    "def people_per_gk(train_data):\n",
    "    train_data = pd.merge(train_data, grunnkrets_age[['grunnkrets_id', 'total_nbr_people']], on='grunnkrets_id', how='left')\n",
    "    train_data['total_nbr_people'] = train_data['total_nbr_people'].fillna(0)\n",
    "    return train_data\n",
    "\n",
    "def people_per_store_in_each_gk(train_data):\n",
    "    train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'nbr_people_per_store_in_grunnkrets']], on='grunnkrets_id', how='left')\n",
    "\n",
    "    #dont know if we need this\n",
    "    train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    train_data['nbr_people_per_store_in_grunnkrets'] = train_data['nbr_people_per_store_in_grunnkrets'].fillna(0)\n",
    "    return train_data\n",
    "\n",
    "\n",
    "def people_per_store_with_same_lvl2_in_each_gk(train_data):\n",
    "    # Number of people per store in each grunnkrets in lv2\n",
    "    counts = train_data[[\"store_id\", \"grunnkrets_id\", \"lv2\"]].groupby(\n",
    "        [\"grunnkrets_id\", \"lv2\"]\n",
    "    ).count().reset_index()\n",
    "    counts.columns = [\"grunnkrets_id\", \"lv2\", \"counts_gr_lv2\"]\n",
    "    train_data = train_data.merge(counts, how=\"left\", on=[\"grunnkrets_id\", \"lv2\"])\n",
    "\n",
    "    #dont know if we need this\n",
    "    train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    return train_data\n",
    "    \n",
    "def people_per_municipality(train_data, test_data):\n",
    "    municipalities = train_data[[\"municipality_name\", \"total_nbr_people\"]].groupby(\n",
    "    [\"municipality_name\"]\n",
    "    ).sum().reset_index()\n",
    "    municipalities = municipalities.rename(columns={'total_nbr_people':'nbr_people_in_municipality'})\n",
    "\n",
    "    # Print distribution to check relevant division into small/medium/large municipality\n",
    "    municipalities = municipalities[municipalities['municipality_name'] != 'No municipality name'] # remove No municipality name (NaN)\n",
    "\n",
    "    #print(municipalities['nbr_people_in_municipality'].describe())\n",
    "    #ax = municipalities.plot.bar(x='municipality_name', y='nbr_people_in_municipality', rot=0)\n",
    "    #print(municipalities)\n",
    "\n",
    "    # Make new column in municipalities for municipality size category, assign categories\n",
    "    conditions = [\n",
    "        (municipalities['nbr_people_in_municipality'] < 1.612750e+03),\n",
    "        (municipalities['nbr_people_in_municipality'] >= 1.612750e+03) & (municipalities['nbr_people_in_municipality'] < 5.731000e+03),\n",
    "        (municipalities['nbr_people_in_municipality'] >= 5.731000e+03) & (municipalities['nbr_people_in_municipality'] < 1.717325e+04),\n",
    "        (municipalities['nbr_people_in_municipality'] >= 1.717325e+04) & (municipalities['nbr_people_in_municipality'] < (2.109973e+06)-1),\n",
    "        (municipalities['nbr_people_in_municipality'] >= (2.109973e+06)-1),\n",
    "    ]\n",
    "    values = ['1', '2', '3', '4', '0']\n",
    "    municipalities['municipality_size_group'] = np.select(conditions, values)\n",
    "    #print(municipalities)\n",
    "    # municipalities['municipality_size_group'].value_counts() # four size categories of 102-103 municipalities in each, category 0 is the 'No municipality name' one\n",
    "\n",
    "    # merge to train data\n",
    "    train_data = pd.merge(train_data, municipalities[['municipality_name', 'municipality_size_group']], on='municipality_name', how='outer')\n",
    "    # merge to test data\n",
    "    test_data = pd.merge(test_data, municipalities[['municipality_name', 'municipality_size_group']], on='municipality_name', how='outer')\n",
    "    return train_data, test_data\n",
    "\n",
    "def people_per_sotre_with_same_lvl2_in_each_muninicipality(train_data):\n",
    "\n",
    "    nbr_in_municipality = train_data[[\"store_id\",\"municipality_name\", \"lv2\"]].groupby(\n",
    "        [\"municipality_name\", \"lv2\"]\n",
    "    ).count().reset_index()\n",
    "    nbr_in_municipality.columns = [\"municipality_name\", \"lv2\", \"counts_municipality_lv2\"]\n",
    "    train_data = train_data.merge(nbr_in_municipality, how=\"left\", on=[\"municipality_name\", \"lv2\"])\n",
    "\n",
    "    #dont know if we need this\n",
    "    train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    return train_data\n",
    "\n",
    "def mean_rev_size_group(train_data, test_data):\n",
    "    mean_rev_munic = train_data[[\"municipality_size_group\", \"revenue\"]].groupby(\n",
    "    [\"municipality_size_group\"]\n",
    "    ).mean().reset_index()\n",
    "    mean_rev_munic = mean_rev_munic.rename(columns={'revenue':'mean_revenue_for_municipality_size_group'})\n",
    "\n",
    "    # merge to train data\n",
    "    train_data = train_data.merge(mean_rev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "    # In case of duplicates, remove them.\n",
    "    train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "\n",
    "    # merge to test data\n",
    "    test_data = test_data.merge(mean_rev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "    # In case of duplicates, remove them.\n",
    "    test_data = test_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    return train_data, test_data\n",
    "\n",
    "def median_rev_size_group(train_data, test_data):\n",
    "    # median rev per municipality size group\n",
    "    median_rev_munic = train_data[[\"municipality_size_group\", \"revenue\"]].groupby(\n",
    "        [\"municipality_size_group\"]\n",
    "    ).median().reset_index()\n",
    "    median_rev_munic = median_rev_munic.rename(columns={'revenue':'median_revenue_for_municipality_size_group'})\n",
    "\n",
    "    # merge to train data\n",
    "    train_data = train_data.merge(median_rev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "    # In case of duplicates, remove them.\n",
    "    train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    # merge to test data\n",
    "    test_data = test_data.merge(median_rev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "    # In case of duplicates, remove them.\n",
    "    test_data = test_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    return train_data, test_data\n",
    "\n",
    "def std_red_size_group(train_data, test_data):\n",
    "    # st dev per municipality size group\n",
    "    stdev_munic = train_data[[\"municipality_size_group\", \"revenue\"]].groupby(\n",
    "        [\"municipality_size_group\"]\n",
    "    ).std().reset_index()\n",
    "    stdev_munic = stdev_munic.rename(columns={'revenue':'st_dev_of_revenue_for_municipality_size_group'})\n",
    "    \n",
    "\n",
    "    # merge to train data\n",
    "    train_data = train_data.merge(stdev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "    # In case of duplicates, remove them.\n",
    "    train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    # merge to test data\n",
    "    test_data = test_data.merge(stdev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "    # In case of duplicates, remove them.\n",
    "    test_data = test_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def mean_rev_municipality(train_data, test_data):\n",
    "    # Mean revenue for municipality and lv2\n",
    "    municipalities_rev = train_data[[\"municipality_name\", \"lv2\", \"revenue\"]].groupby(\n",
    "        [\"municipality_name\", \"lv2\"]\n",
    "    ).mean().reset_index()\n",
    "    municipalities_rev = municipalities_rev.rename(columns={'revenue':'mean_revenue_for_municipality_and_level2'})\n",
    "\n",
    "    # Print distribution to check relevant division into low/medium/high revenue municipality\n",
    "    municipalities_rev = municipalities_rev[municipalities_rev['municipality_name'] != 'No municipality name'] # remove No municipality name (NaN)\n",
    "\n",
    "    #print(municipalities_rev['mean_revenue_for_municipality_and_level2'].describe())\n",
    "    #ax = municipalities_rev.plot.bar(x='municipality_name', y='mean_revenue_for_municipality_and_level2', rot=0)\n",
    "\n",
    "    # Find group splits\n",
    "\n",
    "    # Make new column in municipalities_rev for municipality revenue category, assign categories\n",
    "    conds = [\n",
    "        (municipalities_rev['mean_revenue_for_municipality_and_level2'] < np.log1p(1.931500)),\n",
    "        (municipalities_rev['mean_revenue_for_municipality_and_level2'] >= np.log1p(1.931500)) & (municipalities_rev['mean_revenue_for_municipality_and_level2'] < np.log1p(4.154000)),\n",
    "        (municipalities_rev['mean_revenue_for_municipality_and_level2'] >= np.log1p(4.154000)) & (municipalities_rev['mean_revenue_for_municipality_and_level2'] < np.log1p(8.806000)),\n",
    "        (municipalities_rev['mean_revenue_for_municipality_and_level2'] >= np.log1p(8.806000)),\n",
    "    ]\n",
    "    vals = ['1', '2', '3', '4']\n",
    "    municipalities_rev['municipality_rev_group_lv2'] = np.array(vals)[np.array(conds).argmax(axis=0)] #np.select(conds, vals)\n",
    "\n",
    "    #print(municipalities_rev)\n",
    "    #municipalities_rev['municipality_rev_group_lv2'].value_counts() # Varför en grupp med 0?????\n",
    "\n",
    "    # merge to train data\n",
    "    train_data = pd.merge(train_data, municipalities_rev[['municipality_name', 'municipality_rev_group_lv2']], on='municipality_name', how='outer')\n",
    "\n",
    "    # merge to test data\n",
    "    test_data = pd.merge(test_data, municipalities_rev[['municipality_name', 'municipality_rev_group_lv2']], on='municipality_name', how='outer')\n",
    "\n",
    "    #municipalities_rev['municipality_rev_group_lv2'].value_counts() # Varför en grupp med 0?????\n",
    "    return train_data, test_data\n",
    "\n",
    "# mean rev per municipality rev group lv2\n",
    "def mean_rev_rev_group_lv2(train_data, test_data):\n",
    "    mean_rev_munic_lv2 = train_data[[\"municipality_rev_group_lv2\", \"revenue\"]].groupby(\n",
    "        [\"municipality_rev_group_lv2\"]\n",
    "    ).mean().reset_index()\n",
    "    mean_rev_munic_lv2 = mean_rev_munic_lv2.rename(columns={'revenue':'mean_revenue_for_municipality_rev_group_lv2'})\n",
    "\n",
    "    # merge to train data\n",
    "    train_data = train_data.merge(mean_rev_munic_lv2, how=\"left\", on=[\"municipality_rev_group_lv2\"])\n",
    "    # In case of duplicates, remove them.\n",
    "    train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "\n",
    "    # merge to test data\n",
    "    test_data = test_data.merge(mean_rev_munic_lv2, how=\"left\", on=[\"municipality_rev_group_lv2\"])\n",
    "    # In case of duplicates, remove them.\n",
    "    test_data = test_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORE TO STORE FEATURES\n",
    "def store_dist_lvl2(df):\n",
    "    # create a datafram with all stores extra\n",
    "    test = pd.read_csv('data/stores_test.csv')\n",
    "    train = pd.read_csv('data/stores_train.csv')\n",
    "    extra = pd.read_csv('data/stores_extra.csv')\n",
    "    extra_df = pd.DataFrame()\n",
    "    extra_df = extra_df.append(test).append(train).append(extra)\n",
    "    extra_df = create_lvl(extra_df)\n",
    "\n",
    "    df['num_stores_within_100m_and_same_lvl2'] = 0\n",
    "    df['num_stores_within_500m_and_same_lvl2'] = 0\n",
    "    df['num_stores_within_1km_and_same_lvl2'] = 0\n",
    "    df['num_stores_within_5km_and_same_lvl2'] = 0\n",
    "    df['num_stores_within_10km_and_same_lvl2'] = 0\n",
    "    df['num_stores_within_20km_and_same_lvl2'] = 0\n",
    "    df['closest_competitor_lv2'] = 100.0\n",
    "    num = 0 \n",
    "\n",
    "    for index in range(len(df)):\n",
    "        lat = df._get_value(index,'lat')\n",
    "        lon = df._get_value(index,'lon')\n",
    "        lvl = df._get_value(index, 'lv2')\n",
    "        dist_to_all = dist_to_all_km(lat, lon, extra_df)\n",
    "\n",
    "\n",
    "        count01 = 0\n",
    "        count05 = 0\n",
    "        count1 = 0\n",
    "        count5 = 0\n",
    "        count10 = 0\n",
    "        count20 = 0\n",
    "        closest = 100.0\n",
    "\n",
    "        iter = 0\n",
    "        for number in dist_to_all:\n",
    "            if number < 0.1 and extra_df._get_value(iter, 'lv2') == lvl:\n",
    "                count01 += 1\n",
    "            if number < 0.5 and extra_df._get_value(iter, 'lv2') == lvl:\n",
    "                count05 += 1\n",
    "            if number < 1 and extra_df._get_value(iter, 'lv2') == lvl:\n",
    "                count1 += 1\n",
    "            if number < 5 and extra_df._get_value(iter, 'lv2') == lvl:\n",
    "                count5 += 1\n",
    "            if number < 10 and extra_df._get_value(iter, 'lv2') == lvl:\n",
    "                count10 +=1\n",
    "            if number < 20 and extra_df._get_value(iter, 'lv2') == lvl:\n",
    "                count20 += 1\n",
    "            if number < closest and extra_df._get_value(iter, 'lv2') == lvl and number != 0.0:\n",
    "                closest = number\n",
    "            iter += 1\n",
    "\n",
    "        df._set_value(index, 'num_stores_within_100m_and_same_lvl2', count01)\n",
    "        df._set_value(index, 'num_stores_within_500m_and_same_lvl2', count05)\n",
    "        df._set_value(index, 'num_stores_within_1km_and_same_lvl2', count1)\n",
    "        df._set_value(index, 'num_stores_within_5km_and_same_lvl2', count5)\n",
    "        df._set_value(index, 'num_stores_within_10km_and_same_lvl2', count10)\n",
    "        df._set_value(index, 'num_stores_within_20km_and_same_lvl2', count20)\n",
    "        df._set_value(index, 'closest_competitor_lv2', float(closest))\n",
    "\n",
    "        num+=1 #for runtime tracking only\n",
    "        print(num)\n",
    "    return df\n",
    "\n",
    "\n",
    "def store_dist_lvl3(df):\n",
    "    # create a datafram with all stores extra\n",
    "    test = pd.read_csv('data/stores_test.csv')\n",
    "    train = pd.read_csv('data/stores_train.csv')\n",
    "    extra = pd.read_csv('data/stores_extra.csv')\n",
    "    extra_df = pd.DataFrame()\n",
    "    extra_df = extra_df.append(test).append(train).append(extra)\n",
    "    extra_df = create_lvl(extra_df)\n",
    "\n",
    "    df['num_stores_within_100m_and_same_lvl3'] = 0\n",
    "    df['num_stores_within_500m_and_same_lvl3'] = 0\n",
    "    df['num_stores_within_1km_and_same_lvl3'] = 0\n",
    "    df['num_stores_within_5km_and_same_lvl3'] = 0\n",
    "    df['num_stores_within_10km_and_same_lvl3'] = 0\n",
    "    df['num_stores_within_20km_and_same_lvl3'] = 0\n",
    "    df['closest_competitor_lv3'] = 100.0\n",
    "    num = 0 \n",
    "\n",
    "    for index in range(len(df)):\n",
    "        lat = df._get_value(index,'lat')\n",
    "        lon = df._get_value(index,'lon')\n",
    "        lvl = df._get_value(index, 'lv3')\n",
    "        dist_to_all = dist_to_all_km(lat, lon, extra_df)\n",
    "\n",
    "\n",
    "        count01 = 0\n",
    "        count05 = 0\n",
    "        count1 = 0\n",
    "        count5 = 0\n",
    "        count10 = 0\n",
    "        count20 = 0\n",
    "        closest = 100.0\n",
    "\n",
    "        iter = 0\n",
    "        for number in dist_to_all:\n",
    "            if number < 0.1 and extra_df._get_value(iter, 'lv3') == lvl:\n",
    "                count01 += 1\n",
    "            if number < 0.5 and extra_df._get_value(iter, 'lv3') == lvl:\n",
    "                count05 += 1\n",
    "            if number < 1 and extra_df._get_value(iter, 'lv3') == lvl:\n",
    "                count1 += 1\n",
    "            if number < 5 and extra_df._get_value(iter, 'lv3') == lvl:\n",
    "                count5 += 1\n",
    "            if number < 10 and extra_df._get_value(iter, 'lv3') == lvl:\n",
    "                count10 +=1\n",
    "            if number < 20 and extra_df._get_value(iter, 'lv3') == lvl:\n",
    "                count20 += 1\n",
    "            if number < closest and extra_df._get_value(iter, 'lv3') == lvl and number != 0:\n",
    "                closest = number\n",
    "            iter += 1\n",
    "\n",
    "        df._set_value(index, 'num_stores_within_100m_and_same_lvl3', count01)\n",
    "        df._set_value(index, 'num_stores_within_500m_and_same_lvl3', count05)\n",
    "        df._set_value(index, 'num_stores_within_1km_and_same_lvl3', count1)\n",
    "        df._set_value(index, 'num_stores_within_5km_and_same_lvl3', count5)\n",
    "        df._set_value(index, 'num_stores_within_10km_and_same_lvl3', count10)\n",
    "        df._set_value(index, 'num_stores_within_20km_and_same_lvl3', count20)\n",
    "        df._set_value(index, 'closest_competitor_lv3', float(closest))\n",
    "\n",
    "        num+=1 #for runtime tracking only\n",
    "        print(num)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run once for both train and test data\n",
    "train = rev_to_log(train)\n",
    "lat_long_busstop()\n",
    "prep_gk()\n",
    "\n",
    "train = convert_nan(train)\n",
    "train = combine_grunnkrets_and_data(train)\n",
    "train = create_lvl(train)\n",
    "train = people_per_gk(train)\n",
    "train = people_per_store_in_each_gk(train)\n",
    "train = people_per_store_with_same_lvl2_in_each_gk(train)\n",
    "train = people_per_sotre_with_same_lvl2_in_each_muninicipality(train)\n",
    "train = busstops_wihin_distances(train)\n",
    "train = store_dist_lvl2(train)\n",
    "train = store_dist_lvl3(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = convert_nan(test)\n",
    "test = combine_grunnkrets_and_data(test)\n",
    "test = create_lvl(test)\n",
    "test = people_per_gk(test)\n",
    "test = people_per_store_in_each_gk(test)\n",
    "test = people_per_store_with_same_lvl2_in_each_gk(test)\n",
    "test = people_per_sotre_with_same_lvl2_in_each_muninicipality(test)\n",
    "test = busstops_wihin_distances(test)\n",
    "test = store_dist_lvl2(test)\n",
    "test = store_dist_lvl3(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test = people_per_municipality(train, test)\n",
    "#train, test = mean_rev_size_group(train, test)\n",
    "#train, test = median_rev_size_group(train, test)\n",
    "#train, test = std_red_size_group(train, test)\n",
    "train, test = mean_rev_municipality(train, test)\n",
    "train, test = mean_rev_rev_group_lv2(train, test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save raw data to file\n",
    "\n",
    "test.to_csv('feature_data/testing_set.csv', index=False)\n",
    "train.to_csv('feature_data/training_set.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>chain_name</th>\n",
       "      <th>mall_name</th>\n",
       "      <th>revenue</th>\n",
       "      <th>lv1</th>\n",
       "      <th>lv2</th>\n",
       "      <th>lv3</th>\n",
       "      <th>total_nbr_people</th>\n",
       "      <th>nbr_people_per_store_in_grunnkrets</th>\n",
       "      <th>counts_gr_lv2</th>\n",
       "      <th>...</th>\n",
       "      <th>num_stores_within_1km_and_same_lvl3</th>\n",
       "      <th>num_stores_within_5km_and_same_lvl3</th>\n",
       "      <th>num_stores_within_20km_and_same_lvl3</th>\n",
       "      <th>closest_competitor_lv3</th>\n",
       "      <th>municipality_size_group</th>\n",
       "      <th>mean_revenue_for_municipality_size_group</th>\n",
       "      <th>median_revenue_for_municipality_size_group</th>\n",
       "      <th>st_dev_of_revenue_for_municipality_size_group</th>\n",
       "      <th>municipality_rev_group_lv2</th>\n",
       "      <th>mean_revenue_for_municipality_rev_group_lv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>983540538-974187930-44774</td>\n",
       "      <td>MCDONALDS</td>\n",
       "      <td>Magasinet Drammen</td>\n",
       "      <td>2.944334</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>5.062595</td>\n",
       "      <td>1.420696</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.289699</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.958262</td>\n",
       "      <td>0.921273</td>\n",
       "      <td>0.704684</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.962110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999125026-999139256-472734</td>\n",
       "      <td>No chain</td>\n",
       "      <td>Gulskogen Senter</td>\n",
       "      <td>1.685473</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>4.844187</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1.098387</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.958262</td>\n",
       "      <td>0.921273</td>\n",
       "      <td>0.704684</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.962110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>898083292-898135322-538507</td>\n",
       "      <td>FUJI SUSHI</td>\n",
       "      <td>No mall</td>\n",
       "      <td>2.092234</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>7.005789</td>\n",
       "      <td>4.246708</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.456091</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.958262</td>\n",
       "      <td>0.921273</td>\n",
       "      <td>0.704684</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.962110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>916744765-916758723-821461</td>\n",
       "      <td>No chain</td>\n",
       "      <td>No mall</td>\n",
       "      <td>0.718327</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>6.943122</td>\n",
       "      <td>5.002987</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.456091</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.958262</td>\n",
       "      <td>0.921273</td>\n",
       "      <td>0.704684</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.962110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>916139195-998469740-540508</td>\n",
       "      <td>No chain</td>\n",
       "      <td>No mall</td>\n",
       "      <td>1.571528</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>5.062595</td>\n",
       "      <td>1.420696</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>0.238970</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.958262</td>\n",
       "      <td>0.921273</td>\n",
       "      <td>0.704684</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.962110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12474</th>\n",
       "      <td>998283183-989317857-217707</td>\n",
       "      <td>No chain</td>\n",
       "      <td>No mall</td>\n",
       "      <td>0.400788</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.435085</td>\n",
       "      <td>3.2.1</td>\n",
       "      <td>5.438079</td>\n",
       "      <td>5.438079</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>2.735368</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.904584</td>\n",
       "      <td>0.824146</td>\n",
       "      <td>0.691049</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.941836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12475</th>\n",
       "      <td>996094758-996109313-199649</td>\n",
       "      <td>No chain</td>\n",
       "      <td>No mall</td>\n",
       "      <td>0.217528</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.435085</td>\n",
       "      <td>3.2.1</td>\n",
       "      <td>6.035481</td>\n",
       "      <td>6.035481</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.018567</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.904584</td>\n",
       "      <td>0.824146</td>\n",
       "      <td>0.691049</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.941836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12476</th>\n",
       "      <td>914943868-972886343-442648</td>\n",
       "      <td>No chain</td>\n",
       "      <td>No mall</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.435085</td>\n",
       "      <td>3.2.1</td>\n",
       "      <td>5.568345</td>\n",
       "      <td>5.568345</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.724282</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.904584</td>\n",
       "      <td>0.824146</td>\n",
       "      <td>0.691049</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.941836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12477</th>\n",
       "      <td>911694824-978952933-343891</td>\n",
       "      <td>No chain</td>\n",
       "      <td>No mall</td>\n",
       "      <td>0.136278</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.435085</td>\n",
       "      <td>3.2.4</td>\n",
       "      <td>6.059123</td>\n",
       "      <td>6.059123</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.272859</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.904584</td>\n",
       "      <td>0.824146</td>\n",
       "      <td>0.691049</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.941836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12478</th>\n",
       "      <td>915554695-915594638-773406</td>\n",
       "      <td>No chain</td>\n",
       "      <td>No mall</td>\n",
       "      <td>0.161268</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.458615</td>\n",
       "      <td>3.3.3</td>\n",
       "      <td>4.521789</td>\n",
       "      <td>4.521789</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.430870</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.904584</td>\n",
       "      <td>0.824146</td>\n",
       "      <td>0.691049</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.941836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12479 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         store_id  chain_name          mall_name   revenue  \\\n",
       "0       983540538-974187930-44774   MCDONALDS  Magasinet Drammen  2.944334   \n",
       "1      999125026-999139256-472734    No chain   Gulskogen Senter  1.685473   \n",
       "2      898083292-898135322-538507  FUJI SUSHI            No mall  2.092234   \n",
       "3      916744765-916758723-821461    No chain            No mall  0.718327   \n",
       "4      916139195-998469740-540508    No chain            No mall  1.571528   \n",
       "...                           ...         ...                ...       ...   \n",
       "12474  998283183-989317857-217707    No chain            No mall  0.400788   \n",
       "12475  996094758-996109313-199649    No chain            No mall  0.217528   \n",
       "12476  914943868-972886343-442648    No chain            No mall  0.483660   \n",
       "12477  911694824-978952933-343891    No chain            No mall  0.136278   \n",
       "12478  915554695-915594638-773406    No chain            No mall  0.161268   \n",
       "\n",
       "            lv1       lv2    lv3  total_nbr_people  \\\n",
       "0      0.693147  0.741937  1.1.1          5.062595   \n",
       "1      0.693147  0.741937  1.1.2          4.844187   \n",
       "2      0.693147  0.741937  1.1.2          7.005789   \n",
       "3      0.693147  0.741937  1.1.2          6.943122   \n",
       "4      0.693147  0.741937  1.1.2          5.062595   \n",
       "...         ...       ...    ...               ...   \n",
       "12474  1.386294  1.435085  3.2.1          5.438079   \n",
       "12475  1.386294  1.435085  3.2.1          6.035481   \n",
       "12476  1.386294  1.435085  3.2.1          5.568345   \n",
       "12477  1.386294  1.435085  3.2.4          6.059123   \n",
       "12478  1.386294  1.458615  3.3.3          4.521789   \n",
       "\n",
       "       nbr_people_per_store_in_grunnkrets  counts_gr_lv2  ...  \\\n",
       "0                                1.420696       2.708050  ...   \n",
       "1                                2.079442       0.693147  ...   \n",
       "2                                4.246708       1.609438  ...   \n",
       "3                                5.002987       1.386294  ...   \n",
       "4                                1.420696       2.708050  ...   \n",
       "...                                   ...            ...  ...   \n",
       "12474                            5.438079       0.693147  ...   \n",
       "12475                            6.035481       0.693147  ...   \n",
       "12476                            5.568345       0.693147  ...   \n",
       "12477                            6.059123       0.693147  ...   \n",
       "12478                            4.521789       0.693147  ...   \n",
       "\n",
       "       num_stores_within_1km_and_same_lvl3  \\\n",
       "0                                 0.693147   \n",
       "1                                 0.693147   \n",
       "2                                 1.791759   \n",
       "3                                 1.791759   \n",
       "4                                 1.791759   \n",
       "...                                    ...   \n",
       "12474                             0.693147   \n",
       "12475                             0.693147   \n",
       "12476                             0.693147   \n",
       "12477                             0.693147   \n",
       "12478                             0.693147   \n",
       "\n",
       "       num_stores_within_5km_and_same_lvl3  \\\n",
       "0                                 1.609438   \n",
       "1                                 1.945910   \n",
       "2                                 1.945910   \n",
       "3                                 1.945910   \n",
       "4                                 1.945910   \n",
       "...                                    ...   \n",
       "12474                             0.693147   \n",
       "12475                             0.693147   \n",
       "12476                             0.693147   \n",
       "12477                             0.693147   \n",
       "12478                             0.693147   \n",
       "\n",
       "       num_stores_within_20km_and_same_lvl3  closest_competitor_lv3  \\\n",
       "0                                  2.079442                1.289699   \n",
       "1                                  2.708050                1.098387   \n",
       "2                                  2.708050                0.456091   \n",
       "3                                  2.708050                0.456091   \n",
       "4                                  2.708050                0.238970   \n",
       "...                                     ...                     ...   \n",
       "12474                              2.397895                2.735368   \n",
       "12475                              1.098612                3.018567   \n",
       "12476                              1.609438                2.724282   \n",
       "12477                              0.693147                3.272859   \n",
       "12478                              1.098612                2.430870   \n",
       "\n",
       "       municipality_size_group  mean_revenue_for_municipality_size_group  \\\n",
       "0                     1.609438                                  0.958262   \n",
       "1                     1.609438                                  0.958262   \n",
       "2                     1.609438                                  0.958262   \n",
       "3                     1.609438                                  0.958262   \n",
       "4                     1.609438                                  0.958262   \n",
       "...                        ...                                       ...   \n",
       "12474                 0.693147                                  0.904584   \n",
       "12475                 0.693147                                  0.904584   \n",
       "12476                 0.693147                                  0.904584   \n",
       "12477                 0.693147                                  0.904584   \n",
       "12478                 0.693147                                  0.904584   \n",
       "\n",
       "       median_revenue_for_municipality_size_group  \\\n",
       "0                                        0.921273   \n",
       "1                                        0.921273   \n",
       "2                                        0.921273   \n",
       "3                                        0.921273   \n",
       "4                                        0.921273   \n",
       "...                                           ...   \n",
       "12474                                    0.824146   \n",
       "12475                                    0.824146   \n",
       "12476                                    0.824146   \n",
       "12477                                    0.824146   \n",
       "12478                                    0.824146   \n",
       "\n",
       "       st_dev_of_revenue_for_municipality_size_group  \\\n",
       "0                                           0.704684   \n",
       "1                                           0.704684   \n",
       "2                                           0.704684   \n",
       "3                                           0.704684   \n",
       "4                                           0.704684   \n",
       "...                                              ...   \n",
       "12474                                       0.691049   \n",
       "12475                                       0.691049   \n",
       "12476                                       0.691049   \n",
       "12477                                       0.691049   \n",
       "12478                                       0.691049   \n",
       "\n",
       "       municipality_rev_group_lv2  mean_revenue_for_municipality_rev_group_lv2  \n",
       "0                        1.386294                                     0.962110  \n",
       "1                        1.386294                                     0.962110  \n",
       "2                        1.386294                                     0.962110  \n",
       "3                        1.386294                                     0.962110  \n",
       "4                        1.386294                                     0.962110  \n",
       "...                           ...                                          ...  \n",
       "12474                    0.693147                                     0.941836  \n",
       "12475                    0.693147                                     0.941836  \n",
       "12476                    0.693147                                     0.941836  \n",
       "12477                    0.693147                                     0.941836  \n",
       "12478                    0.693147                                     0.941836  \n",
       "\n",
       "[12479 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('feature_data/training_set.csv')\n",
    "test = pd.read_csv('feature_data/testing_set.csv')\n",
    "\n",
    "def drop_all(train_data):\n",
    "    train_data = train_data.drop(['year', 'store_name', 'plaace_hierarchy_id', 'sales_channel_name', 'grunnkrets_id'], axis=1)\n",
    "    train_data = train_data.drop(['address', 'lat', 'lon', 'municipality_name'], axis=1)\n",
    "    train_data = train_data.drop(['busstops_within_50m', 'num_stores_within_100m_and_same_lvl3', 'busstops_within_100m', 'num_stores_within_100m_and_same_lvl2'], axis = 1)\n",
    "    train_data = train_data.drop(['num_stores_within_500m_and_same_lvl3', 'num_stores_within_10km_and_same_lvl3'], axis=1)\n",
    "    #train_data = train_data.reset_index(drop=True)\n",
    "    return train_data\n",
    "    \n",
    "def remove_zero_rev(train_data):\n",
    "    i = train_data[(train_data.revenue == 0)].index\n",
    "    train_data.drop(i)\n",
    "    train_data = train_data.reset_index()\n",
    "    return train_data\n",
    "    \n",
    "\n",
    "test = drop_all(test)\n",
    "train = drop_all(train)\n",
    "train = remove_zero_revenue(train)\n",
    "\n",
    "def log_all(df):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    for c in [c for c in df.columns if df[c].dtype in numerics]:\n",
    "        df[c] = np.log1p(df[c])\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = log_all(train)\n",
    "train['revenue'] = np.expm1(train['revenue'])\n",
    "test = log_all(test)\n",
    "#train = remove_high_revenue()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dropped data to csv\n",
    "test.to_csv('feature_data/testing_set_dropped.csv', index=False)\n",
    "train.to_csv('feature_data/training_set_dropped.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
