{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import geopy.distance\n",
    "from dis import dis\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import numpy\n",
    "from shapely import wkt\n",
    "from shapely import wkb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('data/stores_train.csv',nrows=1000)\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "grunnkrets_age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "grunnkrets_households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "grunnkrets_income = pd.read_csv('data/grunnkrets_income_households.csv')\n",
    "grunnkrets_stripped = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "plaace_hierarchy = pd.read_csv('data/plaace_hierarchy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Julia\n",
    "\n",
    "# Replace NaN in mall_name column with 'No mall'\n",
    "train_data.mall_name = train_data.mall_name.fillna('No mall')\n",
    "train_data.address = train_data.address.fillna('No address')\n",
    "train_data.chain_name = train_data.chain_name.fillna('No chain')\n",
    "\n",
    "# 'store_name', 'year', 'sales_channel_name', 'address' columns are redundant, remove them\n",
    "train_data = train_data.drop('store_name',axis=1)\n",
    "train_data = train_data.drop('year',axis=1)\n",
    "train_data = train_data.drop('sales_channel_name',axis=1)\n",
    "train_data = train_data.drop('address',axis=1)\n",
    "\n",
    "# Make new column for less specified plaace hierarchy to group data together\n",
    "train_data = pd.merge(train_data, plaace_hierarchy[['plaace_hierarchy_id', 'lv1', 'lv2', 'lv3']], on='plaace_hierarchy_id', how='outer')\n",
    "train_data.isnull().sum().sum()\n",
    "\n",
    "# Dummy variable for mall or no mall\n",
    "train_data.loc[train_data['mall_name'].str.contains(\"No mall\", na=False),'mall_dummy'] = 0\n",
    "train_data.loc[~(train_data['mall_name'].str.contains(\"No mall\", na=False)),'mall_dummy'] = 1\n",
    "train_data.drop(['mall_name'],axis=1, inplace=True)\n",
    "\n",
    "# Sum together the number of people in each grunnkrets\n",
    "grunnkrets_age = grunnkrets_age.drop_duplicates(subset=['grunnkrets_id'], keep='last') # if there is value for 2016 we keep it, otherwise 2015\n",
    "grunnkrets_age = grunnkrets_age.fillna(0)\n",
    "grunnkrets_age = grunnkrets_age.drop('year',axis=1)\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(str)\n",
    "grunnkrets_age['total_nbr_people'] = grunnkrets_age.sum(axis=1) # total number of inhabitants\n",
    "grunnkrets_age['group1'] = grunnkrets_age.iloc[:,1:11].sum(axis=1) # 0-9 years old\n",
    "grunnkrets_age['group2'] = grunnkrets_age.iloc[:,11:21].sum(axis=1) # 10-19 years old etc\n",
    "grunnkrets_age['group3'] = grunnkrets_age.iloc[:,21:31].sum(axis=1)\n",
    "grunnkrets_age['group4'] = grunnkrets_age.iloc[:,31:41].sum(axis=1)\n",
    "grunnkrets_age['group5'] = grunnkrets_age.iloc[:,41:51].sum(axis=1)\n",
    "grunnkrets_age['group6'] = grunnkrets_age.iloc[:,51:61].sum(axis=1)\n",
    "grunnkrets_age['group7'] = grunnkrets_age.iloc[:,61:71].sum(axis=1)\n",
    "grunnkrets_age['group8'] = grunnkrets_age.iloc[:,71:81].sum(axis=1)\n",
    "grunnkrets_age['group9'] = grunnkrets_age.iloc[:,81:92].sum(axis=1) # 80-90 years old\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(int)\n",
    "train_data = pd.merge(train_data, grunnkrets_age[['grunnkrets_id', 'total_nbr_people', 'group1', 'group2', 'group3', 'group4', 'group5', 'group6', 'group7', 'group8', 'group9']], on='grunnkrets_id', how='left')\n",
    "\n",
    "\n",
    "# Number of people per store type (lv2) and grunnkrets\n",
    "\n",
    "number_stores = train_data['grunnkrets_id'].value_counts().rename_axis('grunnkrets_id').reset_index(name='store_counts_total') # Not including NaN (stores without a grunnkrets_id)\n",
    "grunnkrets_stripped = pd.merge(grunnkrets_stripped, number_stores[['grunnkrets_id', 'store_counts_total']], on='grunnkrets_id', how='left')\n",
    "grunnkrets_stripped.store_counts_total = grunnkrets_stripped.store_counts_total.fillna(0)\n",
    "grunnkrets_stripped = pd.merge(grunnkrets_stripped, grunnkrets_age[['grunnkrets_id', 'total_nbr_people']], on='grunnkrets_id', how='left')\n",
    "grunnkrets_stripped['nbr_people_per_store_in_grunnkrets'] = grunnkrets_stripped['total_nbr_people']/grunnkrets_stripped['store_counts_total']\n",
    "train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'nbr_people_per_store_in_grunnkrets']], on='grunnkrets_id', how='left')\n",
    "\n",
    "# Calc how mani is in lvl2\n",
    "counts = train_data[[\"store_id\", \"grunnkrets_id\", \"lv2\"]].groupby(\n",
    "    [\"grunnkrets_id\", \"lv2\"]\n",
    ").count().reset_index()\n",
    "counts.columns = [\"grunnkrets_id\", \"lv2\", \"counts_gr_lv2\"]\n",
    "train_data.merge(counts, how=\"left\", on=[\"grunnkrets_id\", \"lv2\"])\n",
    "\n",
    "#Fix missing values\n",
    "train_data.update(train_data[['total_nbr_people','group1','group2','group3','group4','group5','group6','group7','group8','group9']].fillna(0))\n",
    "train_data.update(train_data[['nbr_people_per_store_in_grunnkrets','nbr_people_per_km2']].fillna(0))\n",
    "\n",
    "#Haakon\n",
    "\n",
    "\n",
    "#number of stores within x radius\n",
    "#sklarn har noe some heter balltree\n",
    "#brukes til til å søke opp k neerest neighbors. \n",
    "def stores_within_distance(distance):\n",
    "    train_data['num_stores_within_distance'] = 0\n",
    "    for index in range(len(train_data)):\n",
    "        lvl1 = train_data._get_value(index,'lv2')\n",
    "        lat1 = train_data._get_value(index,'lat')\n",
    "        lon1 = train_data._get_value(index,'lon')\n",
    "        count = 0\n",
    "        for inx in range(len(train_data)):\n",
    "            lvl2 = train_data._get_value(inx,'lv2')\n",
    "            lat2 = train_data._get_value(inx,'lat')\n",
    "            lon2 = train_data._get_value(inx,'lon')\n",
    "            try:\n",
    "                dist = geopy.distance.geodesic((lat1, lon1), (lat2, lon2)).km #some values have nan in them. must be fixed. \n",
    "                print(lat1, lat2, lon1, lon2)\n",
    "            except:\n",
    "                print(lat1, lat2, lon1, lon2)\n",
    "\n",
    "            if dist < distance and lvl1 == lvl2:\n",
    "                count += 1\n",
    "        train_data._set_value(index, 'num_stores_within_distance', count- 1)\n",
    "\n",
    "#busstops\n",
    "#tar alle busstoppene balltree hele pakka. \n",
    "def busstops_features():\n",
    "    train_data['distance_to_closest_buss_station'] = 0\n",
    "    train_data['importance_level'] = 0\n",
    "    train_data['closest_local_knutepunkt'] = 0\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(busstops)\n",
    "    gdf['geometry'] = gpd.GeoSeries.from_wkt(gdf['geometry'])\n",
    "\n",
    "    for index in range(len(gdf)):\n",
    "        closest = 100000 #large number\n",
    "        importance = \"\"\n",
    "        closest_high_importance = 0\n",
    "        lat = train_data._get_value(index,'lat')\n",
    "        lon = train_data._get_value(index,'lon')\n",
    "        for numbuss in range(len(gdf)):\n",
    "            val = gdf._get_value(index,'geometry')\n",
    "            dist = geopy.distance.geodesic((val.x, val.y), (lat, lon)).km\n",
    "            if dist < closest:\n",
    "                closest = dist\n",
    "                importance = gdf._get_value(index,'importance_level')\n",
    "            if gdf._get_value(index,'importance_level') == 'Lokalt knutepunkt':\n",
    "                closest_high_importance = dist\n",
    "        train_data._set_value(index, 'distance_to_closest_buss_station', closest)\n",
    "        train_data._set_value(index, 'importance_level', importance)\n",
    "        train_data._set_value(index, 'closest_local_knutepunkt', closest_high_importance)\n",
    "\n",
    "#usikker på om det er lov. \n",
    "# ikke stor forskjell på grunnkrets og \n",
    "def postcode():\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    # Display\n",
    "    train_data = pd.read_csv('data/stores_train.csv', nrows= 10)\n",
    "    df = train_data\n",
    "    df['postcode'] = 0\n",
    "    for index in range(len(df)):\n",
    "        lat = df._get_value(index,'lat')\n",
    "        lon = df._get_value(index,'lon')\n",
    "        location = geolocator.reverse(str(lat)+\",\"+str(lon))\n",
    "        address = location.raw['address']\n",
    "        zipcode = address.get('postcode')\n",
    "        df._set_value(index, 'postcode', str(zipcode))\n",
    "    df['postcode']= df.postcode.astype('category')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
