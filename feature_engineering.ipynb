{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import geopy.distance\n",
    "from dis import dis\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import numpy\n",
    "from shapely import wkt\n",
    "from shapely import wkb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('data/stores_train.csv')\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "grunnkrets_age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "grunnkrets_households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "grunnkrets_income = pd.read_csv('data/grunnkrets_income_households.csv')\n",
    "grunnkrets_stripped = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "plaace_hierarchy = pd.read_csv('data/plaace_hierarchy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN in mall_name and chain_name columns with 'No mall' and 'No chain'\n",
    "train_data.mall_name = train_data.mall_name.fillna('No mall')\n",
    "train_data.chain_name = train_data.chain_name.fillna('No chain')\n",
    "\n",
    "# Dummy variable for mall or no mall\n",
    "train_data.loc[train_data['mall_name'].str.contains(\"No mall\", na=False),'mall_dummy'] = 0\n",
    "train_data.loc[~(train_data['mall_name'].str.contains(\"No mall\", na=False)),'mall_dummy'] = 1\n",
    "train_data.drop(['mall_name'],axis=1, inplace=True)\n",
    "\n",
    "# 'store_name', 'year', 'sales_channel_name', 'address' columns are redundant, remove them\n",
    "train_data = train_data.drop('store_name',axis=1)\n",
    "train_data = train_data.drop('year',axis=1)\n",
    "train_data = train_data.drop('sales_channel_name',axis=1)\n",
    "train_data = train_data.drop('address',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'municipality_name']], on='grunnkrets_id', how='left')\n",
    "# we get a bunch of duplicates of store_ids...? Remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = train_data.filter(['chain_name','revenue'], axis=1)\n",
    "chains = chains.groupby('chain_name').mean()\n",
    "chains = chains.rename(columns={'revenue':'mean_revenue_for_chain'})\n",
    "train_data.merge(chains, how=\"left\", on=[\"chain_name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, plaace_hierarchy[['plaace_hierarchy_id', 'lv1', 'lv2', 'lv3']], on='plaace_hierarchy_id', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grunnkrets_age = grunnkrets_age.drop_duplicates(subset=['grunnkrets_id'], keep='last') # if there is value for 2016 we keep it, otherwise 2015\n",
    "grunnkrets_age = grunnkrets_age.fillna(0)\n",
    "grunnkrets_age = grunnkrets_age.drop('year',axis=1)\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(str)\n",
    "grunnkrets_age['total_nbr_people'] = grunnkrets_age.sum(axis=1) # total number of inhabitants\n",
    "grunnkrets_age['group1'] = grunnkrets_age.iloc[:,1:11].sum(axis=1) # 0-9 years old\n",
    "grunnkrets_age['group2'] = grunnkrets_age.iloc[:,11:21].sum(axis=1) # 10-19 years old etc\n",
    "grunnkrets_age['group3'] = grunnkrets_age.iloc[:,21:31].sum(axis=1)\n",
    "grunnkrets_age['group4'] = grunnkrets_age.iloc[:,31:41].sum(axis=1)\n",
    "grunnkrets_age['group5'] = grunnkrets_age.iloc[:,41:51].sum(axis=1)\n",
    "grunnkrets_age['group6'] = grunnkrets_age.iloc[:,51:61].sum(axis=1)\n",
    "grunnkrets_age['group7'] = grunnkrets_age.iloc[:,61:71].sum(axis=1)\n",
    "grunnkrets_age['group8'] = grunnkrets_age.iloc[:,71:81].sum(axis=1)\n",
    "grunnkrets_age['group9'] = grunnkrets_age.iloc[:,81:92].sum(axis=1) # 80-90 years old\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(int)\n",
    "train_data = pd.merge(train_data, grunnkrets_age[['grunnkrets_id', 'total_nbr_people', 'group1', 'group2', 'group3', 'group4', 'group5', 'group6', 'group7', 'group8', 'group9']], on='grunnkrets_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people per store in each grunnkrets regardless of hierarchy\n",
    "number_stores = train_data['grunnkrets_id'].value_counts().rename_axis('grunnkrets_id').reset_index(name='store_counts_total') # Not including NaN (stores without a grunnkrets_id)\n",
    "grunnkrets_stripped = pd.merge(grunnkrets_stripped, number_stores[['grunnkrets_id', 'store_counts_total']], on='grunnkrets_id', how='left')\n",
    "grunnkrets_stripped.store_counts_total = grunnkrets_stripped.store_counts_total.fillna(0)\n",
    "grunnkrets_stripped = pd.merge(grunnkrets_stripped, grunnkrets_age[['grunnkrets_id', 'total_nbr_people']], on='grunnkrets_id', how='left')\n",
    "grunnkrets_stripped['nbr_people_per_store_in_grunnkrets'] = grunnkrets_stripped['total_nbr_people']/grunnkrets_stripped['store_counts_total']\n",
    "train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'nbr_people_per_store_in_grunnkrets']], on='grunnkrets_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people per store in each grunnkrets in lv2\n",
    "counts = train_data[[\"store_id\", \"grunnkrets_id\", \"lv2\"]].groupby(\n",
    "    [\"grunnkrets_id\", \"lv2\"]\n",
    ").count().reset_index()\n",
    "counts.columns = [\"grunnkrets_id\", \"lv2\", \"counts_gr_lv2\"]\n",
    "train_data.merge(counts, how=\"left\", on=[\"grunnkrets_id\", \"lv2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.update(train_data[['total_nbr_people','group1','group2','group3','group4','group5','group6','group7','group8','group9']].fillna(0))\n",
    "#train_data.update(train_data[['nbr_people_per_store_in_grunnkrets','nbr_people_per_km2']].fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['num_stores_within_distance'] = 0\n",
    "for index in range(len(train_data)):\n",
    "    lvl1 = train_data._get_value(index,'lv2')\n",
    "    lat1 = train_data._get_value(index,'lat')\n",
    "    lon1 = train_data._get_value(index,'lon')\n",
    "    count = 0\n",
    "    for inx in range(len(train_data)):\n",
    "        lvl2 = train_data._get_value(inx,'lv2')\n",
    "        lat2 = train_data._get_value(inx,'lat')\n",
    "        lon2 = train_data._get_value(inx,'lon')\n",
    "        try:\n",
    "            dist = geopy.distance.geodesic((lat1, lon1), (lat2, lon2)).km #some values have nan in them. must be fixed. \n",
    "            \n",
    "        except:\n",
    "            dist = 0\n",
    "\n",
    "        if dist < 2 and lvl1 == lvl2:\n",
    "            count += 1\n",
    "    train_data._set_value(index, 'num_stores_within_distance', count- 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['distance_to_closest_buss_station'] = 0\n",
    "train_data['importance_level'] = 0\n",
    "train_data['closest_local_knutepunkt'] = 0\n",
    "\n",
    "gdf = gpd.GeoDataFrame(busstops)\n",
    "gdf['geometry'] = gpd.GeoSeries.from_wkt(gdf['geometry'])\n",
    "\n",
    "for index in range(len(gdf)):\n",
    "    closest = 100000 #large number\n",
    "    importance = \"\"\n",
    "    closest_high_importance = 0\n",
    "    lat = train_data._get_value(index,'lat')\n",
    "    lon = train_data._get_value(index,'lon')\n",
    "    for numbuss in range(len(gdf)):\n",
    "        val = gdf._get_value(index,'geometry')\n",
    "        dist = geopy.distance.geodesic((val.x, val.y), (lat, lon)).km\n",
    "        if dist < closest:\n",
    "            closest = dist\n",
    "            importance = gdf._get_value(index,'importance_level')\n",
    "        if gdf._get_value(index,'importance_level') == 'Lokalt knutepunkt':\n",
    "            closest_high_importance = dist\n",
    "    train_data._set_value(index, 'distance_to_closest_buss_station', closest)\n",
    "    train_data._set_value(index, 'importance_level', importance)\n",
    "    train_data._set_value(index, 'closest_local_knutepunkt', closest_high_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_at_end = ['revenue']\n",
    "train_data = train_data[[c for c in train_data if c not in col_at_end] + [c for c in col_at_end if c in train_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
