{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA enligt https://www.kaggle.com/code/ayushikaushik/eda-regression-analysis#Preprocessing-the-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "train_data = pd.read_csv('data/stores_train.csv')\n",
    "busstops = pd.read_csv('data/busstops_norway.csv')\n",
    "grunnkrets_age = pd.read_csv('data/grunnkrets_age_distribution.csv')\n",
    "grunnkrets_households = pd.read_csv('data/grunnkrets_households_num_persons.csv')\n",
    "grunnkrets_income = pd.read_csv('data/grunnkrets_income_households.csv')\n",
    "grunnkrets_stripped = pd.read_csv('data/grunnkrets_norway_stripped.csv')\n",
    "plaace_hierarchy = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "\n",
    "print(f\"Shape of training data: {train_data.shape}\\nFeatures available: {train_data.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see all the columns in output this can be done.\n",
    "pd.options.display.max_columns=None\n",
    "# To see all rows change max_columns with max_rows\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are missing values => true, so there are\n",
    "train_data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN in mall_name column with 'No mall'\n",
    "train_data.mall_name = train_data.mall_name.fillna('No mall')\n",
    "train_data.address = train_data.address.fillna('No address')\n",
    "train_data.chain_name = train_data.chain_name.fillna('No chain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are missing values => false, so there aren't anymore :)\n",
    "train_data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'store_name', 'year', 'sales_channel_name', 'address' columns are redundant, remove them\n",
    "train_data = train_data.drop('store_name',axis=1)\n",
    "train_data = train_data.drop('year',axis=1)\n",
    "train_data = train_data.drop('sales_channel_name',axis=1)\n",
    "train_data = train_data.drop('address',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data['store_name'] = pd.factorize(train_data['store_name'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_data['revenue'],hist=False)\n",
    "plt.title('Distribution of Target variable')\n",
    "sns.despine() # removes top and right border from the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(train_data['revenue']),hist=False)\n",
    "plt.title('Distribution of Target variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is â‰ˆ normally distributed when plotted in log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column for less specified plaace hierarchy to group data together\n",
    "\n",
    "# train_data.insert(2,'hierarchy', train_data.apply(lambda x: x['plaace_hierarchy_id'][:-4], axis = 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_data[\"hierarchy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['hierarchy'].value_counts()\n",
    "# Issue: we have two 2.8, probably because of one being 2.8. and one 2.8 - can we remove the ending of the strings in a different way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.groupby('hierarchy')['revenue'].mean()\n",
    "# hierarchy seems to affect the revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['chain_name'].value_counts()\n",
    "# 307 different ones, create dummy variables will give too many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['grunnkrets_id'].value_counts()\n",
    "# 3817 different ones, group together somehow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['mall_name'].value_counts()\n",
    "# 488 different ones, but 10579 of the stores are not in a mall\n",
    "# => make dummy variable: one column with 1 for mall and 0 for no mall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variable for mall or no mall\n",
    "\n",
    "# mall_dummy = pd.get_dummies(train_data['mall_name'],drop_first=True)\n",
    "# train_data = pd.concat([train_data,mall_dummy],axis=1)\n",
    "# train_data.drop(['mall_name'],axis=1, inplace=True)\n",
    "\n",
    "train_data.loc[train_data['mall_name'].str.contains(\"No mall\", na=False),'mall_dummy'] = 0\n",
    "train_data.loc[~(train_data['mall_name'].str.contains(\"No mall\", na=False)),'mall_dummy'] = 1\n",
    "train_data.drop(['mall_name'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we work with the geographical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A way to get the zipcode from the lat and lon, based on https://www.geeksforgeeks.org/get-the-city-state-and-country-names-from-latitude-and-longitude-using-python/\n",
    "# and https://gis.stackexchange.com/questions/352961/convert-lat-lon-to-zip-postal-code-using-python\n",
    "# # requires pip install geopy in terminal first\n",
    "\n",
    "import geopy\n",
    "geolocator = geopy.Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# FIRST ATTEMPT\n",
    "# train_data.insert(len(train_data.columns),'zipcode', 0)\n",
    "# # go through the whole columns of lat and lon pairs\n",
    "# for i in range(train_data.shape[0]):\n",
    "#     latitude = str(train_data.loc[i]['lat'])\n",
    "#     longitude = str(train_data.loc[i]['lon'])\n",
    "#     location = geolocator.reverse(latitude+\",\"+longitude)\n",
    "#     address = location.raw['address']\n",
    "#     train_data.loc[i]['zipcode'] = address.get('postcode')\n",
    "# # now we should have the dataframe with an extra column for zipcodes\n",
    "\n",
    "# # SECOND ATTEMPT\n",
    "# def get_zipcode(df, geolocator, lat_field, lon_field):\n",
    "#     location = geolocator.reverse((df[lat_field], df[lon_field]))\n",
    "#     return location.raw['address']['postcode']\n",
    "\n",
    "# zipcodes = train_data.apply(get_zipcode, axis=1, geolocator=geolocator, lat_field='lat', lon_field='lon')\n",
    "# train_data.insert(len(train_data.columns),'zipcode', zipcodes)\n",
    "# # Now we should have the dataframe train_data with a new column for zipcodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEAS/TO DO\n",
    "\n",
    "# Convert categorical columns to numeric\n",
    "# Split into train and test data set\n",
    "# Make new column for distance to nearest busstop based on coordinates and busstops_norway.csv\n",
    "# Make categories for income and age distribution for different grunnkretser, add as columns\n",
    "# Try the sklearn ML models used in the EDA link from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
