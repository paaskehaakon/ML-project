{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import geopy.distance\n",
    "from dis import dis\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import numpy\n",
    "from shapely import wkt\n",
    "from shapely import wkb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_data = pd.read_csv('../data/stores_train.csv')\n",
    "test_data = pd.read_csv('../data/stores_test.csv')\n",
    "busstops = pd.read_csv('../data/busstops_norway.csv')\n",
    "grunnkrets_age = pd.read_csv('../data/grunnkrets_age_distribution.csv')\n",
    "grunnkrets_households = pd.read_csv('../data/grunnkrets_households_num_persons.csv')\n",
    "grunnkrets_income = pd.read_csv('../data/grunnkrets_income_households.csv')\n",
    "grunnkrets_stripped = pd.read_csv('../data/grunnkrets_norway_stripped.csv')\n",
    "plaace_hierarchy = pd.read_csv('../data/plaace_hierarchy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN in mall_name and chain_name columns with 'No mall' and 'No chain'\n",
    "train_data.mall_name = train_data.mall_name.fillna('No mall')\n",
    "train_data.chain_name = train_data.chain_name.fillna('No chain')\n",
    "# For test\n",
    "test_data.mall_name = test_data.mall_name.fillna('No mall')\n",
    "test_data.chain_name = test_data.chain_name.fillna('No chain')\n",
    "\n",
    "# Dummy variable for mall or no mall\n",
    "train_data.loc[train_data['mall_name'].str.contains(\"No mall\", na=False),'mall_dummy'] = 0\n",
    "train_data.loc[~(train_data['mall_name'].str.contains(\"No mall\", na=False)),'mall_dummy'] = 1\n",
    "train_data.drop(['mall_name'],axis=1, inplace=True)\n",
    "# For test\n",
    "test_data.loc[test_data['mall_name'].str.contains(\"No mall\", na=False),'mall_dummy'] = 0\n",
    "test_data.loc[~(test_data['mall_name'].str.contains(\"No mall\", na=False)),'mall_dummy'] = 1\n",
    "test_data.drop(['mall_name'],axis=1, inplace=True)\n",
    "\n",
    "# 'store_name', 'year', 'sales_channel_name', 'address' columns are redundant, remove them\n",
    "train_data = train_data.drop('store_name',axis=1)\n",
    "train_data = train_data.drop('sales_channel_name',axis=1)\n",
    "train_data = train_data.drop('address',axis=1)\n",
    "# For test\n",
    "test_data = test_data.drop('store_name',axis=1)\n",
    "test_data = test_data.drop('sales_channel_name',axis=1)\n",
    "test_data = test_data.drop('address',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add municipality names\n",
    "train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'municipality_name']], on='grunnkrets_id', how='left')\n",
    "# we get a bunch of duplicates of store_ids...? Remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "train_data.municipality_name = train_data.municipality_name.fillna('No municipality name')\n",
    "\n",
    "# For test\n",
    "test_data = pd.merge(test_data, grunnkrets_stripped[['grunnkrets_id', 'municipality_name']], on='grunnkrets_id', how='left')\n",
    "# we get a bunch of duplicates of store_ids...? Remove them.\n",
    "test_data = test_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "test_data.municipality_name = test_data.municipality_name.fillna('No municipality name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total nbr people in each grunnkrets\n",
    "grunnkrets_age = grunnkrets_age.drop_duplicates(subset=['grunnkrets_id'], keep='last') # if there is value for 2016 we keep it, otherwise 2015\n",
    "grunnkrets_age = grunnkrets_age.fillna(0)\n",
    "grunnkrets_age = grunnkrets_age.drop('year',axis=1)\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(str)\n",
    "grunnkrets_age['total_nbr_people'] = grunnkrets_age.sum(axis=1) # total number of inhabitants\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(int)\n",
    "train_data = pd.merge(train_data, grunnkrets_age[['grunnkrets_id', 'total_nbr_people']], on='grunnkrets_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### MUNICIPALITY SIZE GROUPS #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total nbr people in each municipality\n",
    "municipalities = train_data[[\"municipality_name\", \"total_nbr_people\"]].groupby(\n",
    "    [\"municipality_name\"]\n",
    ").sum().reset_index()\n",
    "municipalities = municipalities.rename(columns={'total_nbr_people':'nbr_people_in_municipality'})\n",
    "\n",
    "# Print distribution to check relevant division into small/medium/large municipality\n",
    "municipalities = municipalities[municipalities['municipality_name'] != 'No municipality name'] # remove No municipality name (NaN)\n",
    "\n",
    "#print(municipalities['nbr_people_in_municipality'].describe())\n",
    "#ax = municipalities.plot.bar(x='municipality_name', y='nbr_people_in_municipality', rot=0)\n",
    "#print(municipalities)\n",
    "\n",
    "# Make new column in municipalities for municipality size category, assign categories\n",
    "conditions = [\n",
    "    (municipalities['nbr_people_in_municipality'] < 1.612750e+03),\n",
    "    (municipalities['nbr_people_in_municipality'] >= 1.612750e+03) & (municipalities['nbr_people_in_municipality'] < 5.731000e+03),\n",
    "    (municipalities['nbr_people_in_municipality'] >= 5.731000e+03) & (municipalities['nbr_people_in_municipality'] < 1.717325e+04),\n",
    "    (municipalities['nbr_people_in_municipality'] >= 1.717325e+04) & (municipalities['nbr_people_in_municipality'] < (2.109973e+06)-1),\n",
    "    (municipalities['nbr_people_in_municipality'] >= (2.109973e+06)-1),\n",
    "]\n",
    "values = ['1', '2', '3', '4', '0']\n",
    "municipalities['municipality_size_group'] = np.select(conditions, values)\n",
    "#print(municipalities)\n",
    "# municipalities['municipality_size_group'].value_counts() # four size categories of 102-103 municipalities in each, category 0 is the 'No municipality name' one\n",
    "\n",
    "# merge to train data\n",
    "train_data = pd.merge(train_data, municipalities[['municipality_name', 'municipality_size_group']], on='municipality_name', how='outer')\n",
    "\n",
    "# merge to test data\n",
    "test_data = pd.merge(test_data, municipalities[['municipality_name', 'municipality_size_group']], on='municipality_name', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean rev per municipality size group\n",
    "mean_rev_munic = train_data[[\"municipality_size_group\", \"revenue\"]].groupby(\n",
    "    [\"municipality_size_group\"]\n",
    ").mean().reset_index()\n",
    "mean_rev_munic = mean_rev_munic.rename(columns={'revenue':'mean_revenue_for_municipality_size_group'})\n",
    "\n",
    "# merge to train data\n",
    "train_data = train_data.merge(mean_rev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "# In case of duplicates, remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "\n",
    "# merge to test data\n",
    "test_data = test_data.merge(mean_rev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "# In case of duplicates, remove them.\n",
    "test_data = test_data.drop_duplicates(subset=['store_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median rev per municipality size group\n",
    "median_rev_munic = train_data[[\"municipality_size_group\", \"revenue\"]].groupby(\n",
    "    [\"municipality_size_group\"]\n",
    ").median().reset_index()\n",
    "median_rev_munic = median_rev_munic.rename(columns={'revenue':'median_revenue_for_municipality_size_group'})\n",
    "\n",
    "# merge to train data\n",
    "train_data = train_data.merge(median_rev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "# In case of duplicates, remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "\n",
    "# merge to test data\n",
    "test_data = test_data.merge(median_rev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "# In case of duplicates, remove them.\n",
    "test_data = test_data.drop_duplicates(subset=['store_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st dev per municipality size group\n",
    "stdev_munic = train_data[[\"municipality_size_group\", \"revenue\"]].groupby(\n",
    "    [\"municipality_size_group\"]\n",
    ").std().reset_index()\n",
    "stdev_munic = stdev_munic.rename(columns={'revenue':'st_dev_of_revenue_for_municipality_size_group'})\n",
    "\n",
    "# merge to train data\n",
    "train_data = train_data.merge(stdev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "# In case of duplicates, remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "\n",
    "# merge to test data\n",
    "test_data = test_data.merge(stdev_munic, how=\"left\", on=[\"municipality_size_group\"])\n",
    "# In case of duplicates, remove them.\n",
    "test_data = test_data.drop_duplicates(subset=['store_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### MUNICIPALITY REVENUE GROUPS #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean revenue per municipality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean rev per municipality size group DONE\n",
    "# st dev rev per municipality DONE\n",
    "# median rev per municipality size group DONE\n",
    "# antal folk => stor/medel/liten by => mean/median/stdev i stor/medel/liten by DONE\n",
    "\n",
    "# gruppera kommuner pÃ¥ mean rev => high revenue municipalities/medium revenue municipalities/low revenue municipalities\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
