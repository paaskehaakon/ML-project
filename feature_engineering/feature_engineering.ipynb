{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import geopy.distance\n",
    "from dis import dis\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import numpy\n",
    "from shapely import wkt\n",
    "from shapely import wkb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_data = pd.read_csv('../data/stores_train.csv')\n",
    "busstops = pd.read_csv('../data/busstops_norway.csv')\n",
    "grunnkrets_age = pd.read_csv('../data/grunnkrets_age_distribution.csv')\n",
    "grunnkrets_households = pd.read_csv('../data/grunnkrets_households_num_persons.csv')\n",
    "grunnkrets_income = pd.read_csv('../data/grunnkrets_income_households.csv')\n",
    "grunnkrets_stripped = pd.read_csv('../data/grunnkrets_norway_stripped.csv')\n",
    "plaace_hierarchy = pd.read_csv('../data/plaace_hierarchy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y values to logarithmic scale\n",
    "train_data['revenue'] = np.log1p(train_data['revenue'])\n",
    "train_data.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" #convert them back to normal scale\n",
    "train_data['revenue'] = np.exp(train_data['revenue']) -1\n",
    "train_data.head() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN in mall_name and chain_name columns with 'No mall' and 'No chain'\n",
    "train_data.mall_name = train_data.mall_name.fillna('No mall')\n",
    "train_data.chain_name = train_data.chain_name.fillna('No chain')\n",
    "\n",
    "# Dummy variable for mall or no mall\n",
    "train_data.loc[train_data['mall_name'].str.contains(\"No mall\", na=False),'mall_dummy'] = 0\n",
    "train_data.loc[~(train_data['mall_name'].str.contains(\"No mall\", na=False)),'mall_dummy'] = 1\n",
    "train_data.drop(['mall_name'],axis=1, inplace=True)\n",
    "\n",
    "# 'store_name', 'year', 'sales_channel_name', 'address' columns are redundant, remove them\n",
    "train_data = train_data.drop('store_name',axis=1)\n",
    "train_data = train_data.drop('year',axis=1)\n",
    "train_data = train_data.drop('sales_channel_name',axis=1)\n",
    "train_data = train_data.drop('address',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'municipality_name']], on='grunnkrets_id', how='left')\n",
    "# we get a bunch of duplicates of store_ids...? Remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = train_data.filter(['chain_name','revenue'], axis=1)\n",
    "chains = chains.groupby('chain_name').mean()\n",
    "chains = chains.rename(columns={'revenue':'mean_revenue_for_chain'})\n",
    "train_data.merge(chains, how=\"left\", on=[\"chain_name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, plaace_hierarchy[['plaace_hierarchy_id', 'lv1', 'lv2', 'lv3']], on='plaace_hierarchy_id', how='outer')\n",
    "train_data['lv1']= train_data['lv1'].astype('category')\n",
    "train_data['lv2']= train_data['lv2'].astype('category')\n",
    "train_data['lv3']= train_data['lv3'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grunnkrets_age = grunnkrets_age.drop_duplicates(subset=['grunnkrets_id'], keep='last') # if there is value for 2016 we keep it, otherwise 2015\n",
    "grunnkrets_age = grunnkrets_age.fillna(0)\n",
    "grunnkrets_age = grunnkrets_age.drop('year',axis=1)\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(str)\n",
    "grunnkrets_age['total_nbr_people'] = grunnkrets_age.sum(axis=1) # total number of inhabitants\n",
    "\"\"\" grunnkrets_age['group1'] = grunnkrets_age.iloc[:,1:11].sum(axis=1) # 0-9 years old\n",
    "grunnkrets_age['group2'] = grunnkrets_age.iloc[:,11:21].sum(axis=1) # 10-19 years old etc\n",
    "grunnkrets_age['group3'] = grunnkrets_age.iloc[:,21:31].sum(axis=1)\n",
    "grunnkrets_age['group4'] = grunnkrets_age.iloc[:,31:41].sum(axis=1)\n",
    "grunnkrets_age['group5'] = grunnkrets_age.iloc[:,41:51].sum(axis=1)\n",
    "grunnkrets_age['group6'] = grunnkrets_age.iloc[:,51:61].sum(axis=1)\n",
    "grunnkrets_age['group7'] = grunnkrets_age.iloc[:,61:71].sum(axis=1)\n",
    "grunnkrets_age['group8'] = grunnkrets_age.iloc[:,71:81].sum(axis=1)\n",
    "grunnkrets_age['group9'] = grunnkrets_age.iloc[:,81:92].sum(axis=1) # 80-90 years old \"\"\"\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(int)\n",
    "#train_data = pd.merge(train_data, grunnkrets_age[['grunnkrets_id', 'total_nbr_people', 'group1', 'group2', 'group3', 'group4', 'group5', 'group6', 'group7', 'group8', 'group9']], on='grunnkrets_id', how='left')\n",
    "train_data = pd.merge(train_data, grunnkrets_age[['grunnkrets_id', 'total_nbr_people']], on='grunnkrets_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people per store in each grunnkrets regardless of hierarchy\n",
    "number_stores = train_data['grunnkrets_id'].value_counts().rename_axis('grunnkrets_id').reset_index(name='store_counts_total') # Not including NaN (stores without a grunnkrets_id)\n",
    "grunnkrets_stripped = pd.merge(grunnkrets_stripped, number_stores[['grunnkrets_id', 'store_counts_total']], on='grunnkrets_id', how='left')\n",
    "grunnkrets_stripped.store_counts_total = grunnkrets_stripped.store_counts_total.fillna(0)\n",
    "grunnkrets_stripped = pd.merge(grunnkrets_stripped, grunnkrets_age[['grunnkrets_id', 'total_nbr_people']], on='grunnkrets_id', how='left')\n",
    "grunnkrets_stripped['nbr_people_per_store_in_grunnkrets'] = grunnkrets_stripped['total_nbr_people']/grunnkrets_stripped['store_counts_total']\n",
    "train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'nbr_people_per_store_in_grunnkrets']], on='grunnkrets_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people per store in each grunnkrets in lv2\n",
    "counts = train_data[[\"store_id\", \"grunnkrets_id\", \"lv2\"]].groupby(\n",
    "    [\"grunnkrets_id\", \"lv2\"]\n",
    ").count().reset_index()\n",
    "counts.columns = [\"grunnkrets_id\", \"lv2\", \"counts_gr_lv2\"]\n",
    "train_data = train_data.merge(counts, how=\"left\", on=[\"grunnkrets_id\", \"lv2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.update(train_data[['total_nbr_people','group1','group2','group3','group4','group5','group6','group7','group8','group9']].fillna(0))\n",
    "#train_data.update(train_data[['nbr_people_per_store_in_grunnkrets','nbr_people_per_km2']].fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stores in same lv2 in each municipality\n",
    "nbr_in_municipality = train_data[[\"store_id\",\"municipality_name\", \"lv2\"]].groupby(\n",
    "    [\"municipality_name\", \"lv2\"]\n",
    ").count().reset_index()\n",
    "nbr_in_municipality.columns = [\"municipality_name\", \"lv2\", \"counts_municipality_lv2\"]\n",
    "train_data = train_data.merge(nbr_in_municipality, how=\"left\", on=[\"municipality_name\", \"lv2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean revenue for each lv1 in each municipality\n",
    "municipalities = train_data[[\"municipality_name\", \"lv1\", \"revenue\"]].groupby(\n",
    "    [\"municipality_name\", \"lv1\"]\n",
    ").mean().reset_index()\n",
    "municipalities = municipalities.rename(columns={'revenue':'mean_revenue_for_municipality_and_level1'})\n",
    "train_data = train_data.merge(municipalities, how=\"left\", on=[\"municipality_name\", \"lv1\"])\n",
    "# we get a bunch of duplicates of store_ids...? Remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean revenue for each lv2 in each municipality\n",
    "municipalities = train_data[[\"municipality_name\", \"lv2\", \"revenue\"]].groupby(\n",
    "    [\"municipality_name\", \"lv2\"]\n",
    ").mean().reset_index()\n",
    "municipalities = municipalities.rename(columns={'revenue':'mean_revenue_for_municipality_and_level2'})\n",
    "train_data = train_data.merge(municipalities, how=\"left\", on=[\"municipality_name\", \"lv2\"])\n",
    "# we get a bunch of duplicates of store_ids...? Remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean revenue for each lv3 in each municipality\n",
    "municipalities = train_data[[\"municipality_name\", \"lv3\", \"revenue\"]].groupby(\n",
    "    [\"municipality_name\", \"lv3\"]\n",
    ").mean().reset_index()\n",
    "municipalities = municipalities.rename(columns={'revenue':'mean_revenue_for_municipality_and_level3'})\n",
    "train_data = train_data.merge(municipalities, how=\"left\", on=[\"municipality_name\", \"lv3\"])\n",
    "# we get a bunch of duplicates of store_ids...? Remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_at_end = ['revenue']\n",
    "train_data = train_data[[c for c in train_data if c not in col_at_end] + [c for c in col_at_end if c in train_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(train_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all the features we dont use for our model\n",
    "#train_data = train_data.drop('store_id',axis=1)\n",
    "train_data = train_data.drop('plaace_hierarchy_id',axis=1)\n",
    "#train_data = train_data.drop('grunnkrets_id',axis=1)\n",
    "train_data = train_data.drop('chain_name',axis=1)\n",
    "train_data = train_data.drop('municipality_name',axis=1)\n",
    "train_data = train_data.drop('lv3',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('../data/modified_data.csv')\n",
    "train_data.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
