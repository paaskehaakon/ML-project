{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA enligt https://www.kaggle.com/code/ayushikaushik/eda-regression-analysis#Preprocessing-the-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "train_data = pd.read_csv('/home/paaske/Documents/ML-project/data//stores_train.csv')\n",
    "busstops = pd.read_csv('/home/paaske/Documents/ML-project/data//busstops_norway.csv')\n",
    "grunnkrets_age = pd.read_csv('/home/paaske/Documents/ML-project/data//grunnkrets_age_distribution.csv')\n",
    "grunnkrets_households = pd.read_csv('/home/paaske/Documents/ML-project/data//grunnkrets_households_num_persons.csv')\n",
    "grunnkrets_income = pd.read_csv('/home/paaske/Documents/ML-project/data//grunnkrets_income_households.csv')\n",
    "grunnkrets_stripped = pd.read_csv('/home/paaske/Documents/ML-project/data//grunnkrets_norway_stripped.csv')\n",
    "plaace_hierarchy = pd.read_csv('/home/paaske/Documents/ML-project/data//plaace_hierarchy.csv')\n",
    "\n",
    "print(f\"Shape of training data: {train_data.shape}\\nFeatures available: {train_data.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see all the columns in output this can be done.\n",
    "pd.options.display.max_columns=None\n",
    "# To see all rows change max_columns with max_rows\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are missing values => true, so there are\n",
    "train_data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN in mall_name column with 'No mall'\n",
    "train_data.mall_name = train_data.mall_name.fillna('No mall')\n",
    "train_data.address = train_data.address.fillna('No address')\n",
    "train_data.chain_name = train_data.chain_name.fillna('No chain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are missing values => false, so there aren't anymore :)\n",
    "train_data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'store_name', 'year', 'sales_channel_name', 'address' columns are redundant, remove them\n",
    "train_data = train_data.drop('store_name',axis=1)\n",
    "train_data = train_data.drop('year',axis=1)\n",
    "train_data = train_data.drop('sales_channel_name',axis=1)\n",
    "train_data = train_data.drop('address',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data['store_name'] = pd.factorize(train_data['store_name'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_data['revenue'],hist=False)\n",
    "plt.title('Distribution of Target variable')\n",
    "sns.despine() # removes top and right border from the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(train_data['revenue']),hist=False)\n",
    "plt.title('Distribution of Target variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is â‰ˆ normally distributed when plotted in log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column for less specified plaace hierarchy to group data together\n",
    "train_data = pd.merge(train_data, plaace_hierarchy[['plaace_hierarchy_id', 'lv1', 'lv2', 'lv3']], on='plaace_hierarchy_id', how='outer')\n",
    "train_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are missing values\n",
    "train_data.isnull().sum().any() # True\n",
    "train_data.update(train_data[['plaace_hierarchy_id','lv1','lv2','lv3']].fillna(0))\n",
    "train_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=train_data[\"lv2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['lv2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.groupby('lv2')['revenue'].mean()\n",
    "# hierarchy seems to affect the revenue\n",
    "# Problem: why NaN on 1.5 and 3.1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['lv2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['chain_name'].value_counts()\n",
    "# 307 different ones, create dummy variables will give too many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['grunnkrets_id'].value_counts()\n",
    "# 3817 different ones, group together somehow? Municipality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['mall_name'].value_counts()\n",
    "# 488 different ones, but 10579 of the stores are not in a mall\n",
    "# => make dummy variable: one column with 1 for mall and 0 for no mall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variable for mall or no mall\n",
    "\n",
    "# This makes dummy variables for each mall with 1 and 0\n",
    "# mall_dummy = pd.get_dummies(train_data['mall_name'],drop_first=True)\n",
    "# train_data = pd.concat([train_data,mall_dummy],axis=1)\n",
    "# train_data.drop(['mall_name'],axis=1, inplace=True)\n",
    "\n",
    "train_data.loc[train_data['mall_name'].str.contains(\"No mall\", na=False),'mall_dummy'] = 0\n",
    "train_data.loc[~(train_data['mall_name'].str.contains(\"No mall\", na=False)),'mall_dummy'] = 1\n",
    "train_data.drop(['mall_name'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum together the number of people in each grunnkrets\n",
    "grunnkrets_age = grunnkrets_age.drop_duplicates(subset=['grunnkrets_id'], keep='last') # if there is value for 2016 we keep it, otherwise 2015\n",
    "grunnkrets_age = grunnkrets_age.fillna(0)\n",
    "grunnkrets_age = grunnkrets_age.drop('year',axis=1)\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(str)\n",
    "grunnkrets_age['total_nbr_people'] = grunnkrets_age.sum(axis=1) # total number of inhabitants\n",
    "grunnkrets_age['group1'] = grunnkrets_age.iloc[:,1:11].sum(axis=1) # 0-9 years old\n",
    "grunnkrets_age['group2'] = grunnkrets_age.iloc[:,11:21].sum(axis=1) # 10-19 years old etc\n",
    "grunnkrets_age['group3'] = grunnkrets_age.iloc[:,21:31].sum(axis=1)\n",
    "grunnkrets_age['group4'] = grunnkrets_age.iloc[:,31:41].sum(axis=1)\n",
    "grunnkrets_age['group5'] = grunnkrets_age.iloc[:,41:51].sum(axis=1)\n",
    "grunnkrets_age['group6'] = grunnkrets_age.iloc[:,51:61].sum(axis=1)\n",
    "grunnkrets_age['group7'] = grunnkrets_age.iloc[:,61:71].sum(axis=1)\n",
    "grunnkrets_age['group8'] = grunnkrets_age.iloc[:,71:81].sum(axis=1)\n",
    "grunnkrets_age['group9'] = grunnkrets_age.iloc[:,81:92].sum(axis=1) # 80-90 years old\n",
    "grunnkrets_age['grunnkrets_id'] = grunnkrets_age['grunnkrets_id'].astype(int)\n",
    "\n",
    "train_data = pd.merge(train_data, grunnkrets_age[['grunnkrets_id', 'total_nbr_people', 'group1', 'group2', 'group3', 'group4', 'group5', 'group6', 'group7', 'group8', 'group9']], on='grunnkrets_id', how='left')\n",
    "# print(train_data.isnull().sum().sum())\n",
    "# Problem: We get lots of NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people per store type (lv2) and grunnkrets\n",
    "\n",
    "# In dataframe grunnkrets_stripped, add column for number of stores total\n",
    "number_stores = train_data['grunnkrets_id'].value_counts().rename_axis('grunnkrets_id').reset_index(name='store_counts_total') # Not including NaN (stores without a grunnkrets_id)\n",
    "grunnkrets_stripped = pd.merge(grunnkrets_stripped, number_stores[['grunnkrets_id', 'store_counts_total']], on='grunnkrets_id', how='left')\n",
    "grunnkrets_stripped.store_counts_total = grunnkrets_stripped.store_counts_total.fillna(0)\n",
    "\n",
    "# Different way to do the above, same result\n",
    "# grunnkrets_stripped['number_stores_total'] = 0\n",
    "# for i in range(len(number_stores)):\n",
    "#     id = number_stores._get_value(i,'grunnkrets_id')\n",
    "#     nbr = number_stores._get_value(i,'counts')\n",
    "#     grunnkrets_stripped['number_stores_total'].mask(grunnkrets_stripped['grunnkrets_id'] == id, nbr, inplace=True)\n",
    "\n",
    "# In dataframe grunnkrets_stripped, add column for number of people in the grunnkrets\n",
    "grunnkrets_stripped = pd.merge(grunnkrets_stripped, grunnkrets_age[['grunnkrets_id', 'total_nbr_people']], on='grunnkrets_id', how='left')\n",
    "\n",
    "# In dataframe grunnkrets_stripped, add column for number of people per store in total\n",
    "grunnkrets_stripped['nbr_people_per_store_in_grunnkrets'] = grunnkrets_stripped['total_nbr_people']/grunnkrets_stripped['store_counts_total']\n",
    "\n",
    "# In dataframe train_data, add column for number of people per store in total\n",
    "train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'nbr_people_per_store_in_grunnkrets']], on='grunnkrets_id', how='left')\n",
    "\n",
    "\n",
    "# In dataframe grunnkrets_stripped, add column for number of stores in each category in lv2\n",
    "# In dataframe grunnkrets_stripped, add column for number of people per store in each category in lv2\n",
    "# In dataframe train_data, add column for number of people per store in each category in lv2 in each grunnkrets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train_data[[\"store_id\", \"grunnkrets_id\", \"lv2\"]].groupby(\n",
    "    [\"grunnkrets_id\", \"lv2\"]\n",
    ").count().reset_index()\n",
    "counts.columns = [\"grunnkrets_id\", \"lv2\", \"counts_gr_lv2\"]\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.merge(counts, how=\"left\", on=[\"grunnkrets_id\", \"lv2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people per area unit per grunnkrets\n",
    "grunnkrets_stripped['nbr_people_per_km2'] = grunnkrets_stripped['total_nbr_people']/grunnkrets_stripped['area_km2']\n",
    "train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'nbr_people_per_km2']], on='grunnkrets_id', how='left')\n",
    "# we get a bunch of duplicates of store_ids...? Remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.update(train_data[['total_nbr_people','group1','group2','group3','group4','group5','group6','group7','group8','group9']].fillna(0))\n",
    "train_data.update(train_data[['nbr_people_per_store_in_grunnkrets','nbr_people_per_km2']].fillna(0))\n",
    "train_data.chain_name = train_data.chain_name.fillna('No chain')\n",
    "# train_data['chain_name'] = train_data['chain_name'].replace(1,'No chain')\n",
    "train_data['chain_name'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add municipality column to train_data\n",
    "train_data = pd.merge(train_data, grunnkrets_stripped[['grunnkrets_id', 'municipality_name']], on='grunnkrets_id', how='left')\n",
    "# we get a bunch of duplicates of store_ids...? Remove them.\n",
    "train_data = train_data.drop_duplicates(subset=['store_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with mean revenue for each chain\n",
    "# Obs: mean revenue is listed for stores with No chain as well!\n",
    "chains = train_data.filter(['chain_name','revenue'], axis=1)\n",
    "chains = chains.groupby('chain_name').mean()\n",
    "chains = chains.rename(columns={'revenue':'mean_revenue_for_chain'})\n",
    "train_data.merge(chains, how=\"left\", on=[\"chain_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are missing values\n",
    "train_data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEOGRAPHICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A way to get the zipcode from the lat and lon, based on https://www.geeksforgeeks.org/get-the-city-state-and-country-names-from-latitude-and-longitude-using-python/\n",
    "# and https://gis.stackexchange.com/questions/352961/convert-lat-lon-to-zip-postal-code-using-python\n",
    "# # requires pip install geopy in terminal first\n",
    "\n",
    "# import geopy\n",
    "# geolocator = geopy.Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# # FIRST ATTEMPT\n",
    "# train_data.insert(len(train_data.columns),'zipcode', 0)\n",
    "# # go through the whole columns of lat and lon pairs\n",
    "# for i in range(train_data.shape[0]):\n",
    "#     latitude = str(train_data.loc[i]['lat'])\n",
    "#     longitude = str(train_data.loc[i]['lon'])\n",
    "#     location = geolocator.reverse(latitude+\",\"+longitude)\n",
    "#     address = location.raw['address']\n",
    "#     train_data.loc[i]['zipcode'] = address.get('postcode')\n",
    "# # now we should have the dataframe with an extra column for zipcodes\n",
    "\n",
    "# # SECOND ATTEMPT\n",
    "# def get_zipcode(df, geolocator, lat_field, lon_field):\n",
    "#     location = geolocator.reverse((df[lat_field], df[lon_field]))\n",
    "#     return location.raw['address']['postcode']\n",
    "\n",
    "# zipcodes = train_data.apply(get_zipcode, axis=1, geolocator=geolocator, lat_field='lat', lon_field='lon')\n",
    "# train_data.insert(len(train_data.columns),'zipcode', zipcodes)\n",
    "# # Now we should have the dataframe train_data with a new column for zipcodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEAS/TO DO\n",
    "\n",
    "# Convert categorical columns to numeric\n",
    "# Split into train and test data set\n",
    "# Make new column for distance to nearest busstop based on coordinates and busstops_norway.csv\n",
    "# Make categories for income and age distribution for different grunnkretser, add as columns\n",
    "# Try the sklearn ML models used in the EDA link from Kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
